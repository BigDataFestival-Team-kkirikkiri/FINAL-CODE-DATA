{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "639f7758",
   "metadata": {},
   "source": [
    "# 파일 설명 \n",
    "- 특정 날짜의 요약된 뉴스 기사 데이터(news_classified_hybe 외 3개의 SUMMARY_2 열)들에서 키워드를 추출하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807597c4",
   "metadata": {},
   "source": [
    "# 패키지 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155aaf25",
   "metadata": {},
   "source": [
    "## Packages for spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c481a651",
   "metadata": {},
   "source": [
    "- 다국어를 위해 필요한 패키지 다운 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160cee27",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xx-ent-wiki-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/xx_ent_wiki_sm-3.6.0/xx_ent_wiki_sm-3.6.0-py3-none-any.whl (11.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from xx-ent-wiki-sm==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (4.64.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (6.4.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (1.10.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (21.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: jinja2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: setuptools in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (61.2.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (8.1.12)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (1.22.4)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (1.26.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('xx_ent_wiki_sm')\n",
      "Collecting xx-sent-ud-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/xx_sent_ud_sm-3.6.0/xx_sent_ud_sm-3.6.0-py3-none-any.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from xx-sent-ud-sm==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: setuptools in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (61.2.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (1.22.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (8.1.12)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (6.4.0)\n",
      "Requirement already satisfied: jinja2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (1.10.12)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (4.64.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (3.0.12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (2023.5.7)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy<3.7.0,>=3.6.0->xx-sent-ud-sm==3.6.0) (2.0.1)\n",
      "Installing collected packages: xx-sent-ud-sm\n",
      "Successfully installed xx-sent-ud-sm-3.6.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('xx_sent_ud_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download xx_ent_wiki_sm\n",
    "!python -m spacy download xx_sent_ud_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e06b5b9a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: jinja2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.22.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.12)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.64.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
      "Requirement already satisfied: setuptools in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (61.2.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (21.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.7.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.6.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87536998",
   "metadata": {},
   "source": [
    "## Packages for Summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd441283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: summa in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy>=0.19 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from summa) (1.7.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from scipy>=0.19->summa) (1.22.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install summa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3a65ea",
   "metadata": {},
   "source": [
    "## Packages for keyBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68217b6d",
   "metadata": {},
   "source": [
    "- 참고: https://insightcampus.co.kr/2021/07/08/keybert%EB%A1%9C-%EA%B4%80%EB%A0%A8-%ED%82%A4%EC%9B%8C%EB%93%9C-%EC%B6%94%EC%B6%9C%ED%95%98%EA%B8%B0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bc27fe5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keybert\n",
      "  Downloading keybert-0.7.0.tar.gz (21 kB)\n",
      "Collecting sentence-transformers>=0.3.8\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from keybert) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from keybert) (1.22.4)\n",
      "Collecting rich>=10.4.0\n",
      "  Downloading rich-13.5.2-py3-none-any.whl (239 kB)\n",
      "\u001b[K     |████████████████████████████████| 239 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading Pygments-2.16.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.22.2->keybert) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.22.2->keybert) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.22.2->keybert) (1.1.0)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=0.3.8->keybert) (4.64.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=0.3.8->keybert) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=0.3.8->keybert) (0.15.2)\n",
      "Requirement already satisfied: nltk in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=0.3.8->keybert) (3.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp39-cp39-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[K     |████████████████████████████████| 268 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2022.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (6.0)\n",
      "Requirement already satisfied: filelock in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.6.0)\n",
      "Requirement already satisfied: requests in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.31.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.0.4)\n",
      "Requirement already satisfied: jinja2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (3.1.2)\n",
      "Requirement already satisfied: sympy in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (1.10.1)\n",
      "Requirement already satisfied: networkx in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (2.7.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-macosx_10_11_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2022.3.15)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.3-cp39-cp39-macosx_10_11_x86_64.whl (404 kB)\n",
      "\u001b[K     |████████████████████████████████| 404 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (2.0.1)\n",
      "Requirement already satisfied: click in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers>=0.3.8->keybert) (8.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (1.26.9)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (1.2.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (9.0.1)\n",
      "Building wheels for collected packages: keybert, sentence-transformers\n",
      "  Building wheel for keybert (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keybert: filename=keybert-0.7.0-py3-none-any.whl size=23799 sha256=eacea09f72beca9418b86129974416c0d3a2b35a67e9bd9a1b24f0b2eb8925f6\n",
      "  Stored in directory: /Users/yusolcho/Library/Caches/pip/wheels/68/aa/41/82025d89b0eb97484c9ac7d527abf596765c41733af79f86b0\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125940 sha256=f32e300fa9d64e0e359b030aedffd6db983ec821636f149aa2bc99d3f23b9232\n",
      "  Stored in directory: /Users/yusolcho/Library/Caches/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built keybert sentence-transformers\n",
      "Installing collected packages: tokenizers, safetensors, mdurl, huggingface-hub, transformers, sentencepiece, pygments, markdown-it-py, sentence-transformers, rich, keybert\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\u001b[0m\n",
      "Successfully installed huggingface-hub-0.16.4 keybert-0.7.0 markdown-it-py-3.0.0 mdurl-0.1.2 pygments-2.16.1 rich-13.5.2 safetensors-0.3.3 sentence-transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.33.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keybert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a82a413",
   "metadata": {},
   "source": [
    "## Packages for konlpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "812a3bd0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: konlpy in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.6 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from konlpy) (1.22.4)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from konlpy) (4.9.3)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from konlpy) (1.4.1)\n",
      "Requirement already satisfied: packaging in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f417f5b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: JPype1 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (1.4.1)\n",
      "Requirement already satisfied: packaging in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from JPype1) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/yusolcho/opt/anaconda3/lib/python3.9/site-packages (from packaging->JPype1) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install JPype1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8aa649c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy # 키워드 추출 모듈 \n",
    "import summa\n",
    "from summa import keywords\n",
    "from keybert import KeyBERT\n",
    "from konlpy.tag import Kkma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0ba881",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f59dcf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 \n",
    "news_hybe = pd.read_excel(\"../data/News/news_classified_hybe.xlsx\")\n",
    "news_sm = pd.read_excel(\"../data/News/news_classified_sm.xlsx\")\n",
    "news_yg = pd.read_excel(\"../data/News/news_classified_yg.xlsx\")\n",
    "news_jyp = pd.read_excel(\"../data/News/news_classified_jyp.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e5b6c888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NEWS_YM</th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>WRITER</th>\n",
       "      <th>SUBCATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>IMPORTANCE</th>\n",
       "      <th>ITEM_NAME</th>\n",
       "      <th>TAG_LIST</th>\n",
       "      <th>PARSED CONTENT</th>\n",
       "      <th>LENGTH_SUM</th>\n",
       "      <th>SUMMARY</th>\n",
       "      <th>SUMMARY_2</th>\n",
       "      <th>SENTIMENT_NEGATIVE</th>\n",
       "      <th>SENTIMENT_NEUTRAL</th>\n",
       "      <th>SENTIMENT_POSITIVE</th>\n",
       "      <th>DATE_NEW</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>COMPANY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202303</td>\n",
       "      <td>2023-03-03 13:40:44</td>\n",
       "      <td>매일경제</td>\n",
       "      <td>기술</td>\n",
       "      <td>하이브의 SM 인수, '적대적 M&amp;A' 성격 두고 방시혁·SM 충돌</td>\n",
       "      <td>29.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>의사| 독점</td>\n",
       "      <td>방시혁 하이브 의장이 미국 CNN 방송에 출연해 SM엔터테인먼트 인수전을 적대적 M...</td>\n",
       "      <td>2326</td>\n",
       "      <td>해외 언론 인터뷰를 통해 방 의장의 입장이 알려진 건 지난 2월 10일 지분인수 발...</td>\n",
       "      <td>해외 언론 인터뷰를 통해 방 의장의 입장이 알려진 건 지분인수 발표 당일 이수만 전...</td>\n",
       "      <td>95.182945</td>\n",
       "      <td>4.809798</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>2023-03-03</td>\n",
       "      <td>금</td>\n",
       "      <td>-95.175687</td>\n",
       "      <td>HYBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202304</td>\n",
       "      <td>2023-04-14 09:22:37</td>\n",
       "      <td>eDaily</td>\n",
       "      <td>경제</td>\n",
       "      <td>[특징주]엔터株, K-팝 약진 속 일제히 강세</td>\n",
       "      <td>27.41</td>\n",
       "      <td>JYP Ent.|하이브|와이지엔터테인먼트|에스엠</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[이데일리 이용성 기자] 올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객...</td>\n",
       "      <td>2332</td>\n",
       "      <td>올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를...</td>\n",
       "      <td>올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를...</td>\n",
       "      <td>0.024469</td>\n",
       "      <td>0.035980</td>\n",
       "      <td>99.939550</td>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>금</td>\n",
       "      <td>99.915081</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NEWS_YM           DATE_TIME  WRITER SUBCATEGORY  \\\n",
       "0   202303 2023-03-03 13:40:44    매일경제          기술   \n",
       "1   202304 2023-04-14 09:22:37  eDaily          경제   \n",
       "\n",
       "                                   TITLE  IMPORTANCE  \\\n",
       "0  하이브의 SM 인수, '적대적 M&A' 성격 두고 방시혁·SM 충돌       29.27   \n",
       "1              [특징주]엔터株, K-팝 약진 속 일제히 강세       27.41   \n",
       "\n",
       "                    ITEM_NAME TAG_LIST  \\\n",
       "0                         NaN   의사| 독점   \n",
       "1  JYP Ent.|하이브|와이지엔터테인먼트|에스엠      NaN   \n",
       "\n",
       "                                      PARSED CONTENT  LENGTH_SUM  \\\n",
       "0  방시혁 하이브 의장이 미국 CNN 방송에 출연해 SM엔터테인먼트 인수전을 적대적 M...        2326   \n",
       "1  [이데일리 이용성 기자] 올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객...        2332   \n",
       "\n",
       "                                             SUMMARY  \\\n",
       "0  해외 언론 인터뷰를 통해 방 의장의 입장이 알려진 건 지난 2월 10일 지분인수 발...   \n",
       "1  올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를...   \n",
       "\n",
       "                                           SUMMARY_2  SENTIMENT_NEGATIVE  \\\n",
       "0  해외 언론 인터뷰를 통해 방 의장의 입장이 알려진 건 지분인수 발표 당일 이수만 전...           95.182945   \n",
       "1  올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를...            0.024469   \n",
       "\n",
       "   SENTIMENT_NEUTRAL  SENTIMENT_POSITIVE   DATE_NEW DAY  SENTIMENT COMPANY  \n",
       "0           4.809798            0.007258 2023-03-03   금 -95.175687    HYBE  \n",
       "1           0.035980           99.939550 2023-04-14   금  99.915081     ALL  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 확인 \n",
    "news_hybe.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe518862",
   "metadata": {},
   "source": [
    "# spaCy 모듈 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee58a95",
   "metadata": {},
   "source": [
    "(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85b811e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해외, 언론, 인터뷰를\n"
     ]
    }
   ],
   "source": [
    "# spaCy 모델 로드\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# 'SUMMARY_2' 변수에 있는 기사 요약문\n",
    "summary = news_hybe['SUMMARY_2'].iloc[0]\n",
    "\n",
    "# spaCy를 사용하여 문장을 처리하고 키워드 추출\n",
    "doc = nlp(summary)\n",
    "\n",
    "# 키워드 추출\n",
    "keywords = [token.text for token in doc if not token.is_stop and token.is_alpha]\n",
    "\n",
    "# 상위 3개의 키워드 선택 (또는 원하는 수로 조정)\n",
    "top_keywords = keywords[:3]\n",
    "\n",
    "# 'KEYWORD' 변수에 키워드 저장\n",
    "KEYWORD = ', '.join(top_keywords)\n",
    "\n",
    "# 결과 출력\n",
    "print(KEYWORD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebde52f",
   "metadata": {},
   "source": [
    "(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35753510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "올해, 국내, 엔터주들의\n"
     ]
    }
   ],
   "source": [
    "# spaCy 모델 로드\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# 'SUMMARY_2' 변수에 있는 기사 요약문\n",
    "summary = news_hybe['SUMMARY_2'].iloc[1]\n",
    "\n",
    "# spaCy를 사용하여 문장을 처리하고 키워드 추출\n",
    "doc = nlp(summary)\n",
    "\n",
    "# 키워드 추출\n",
    "keywords = [token.text for token in doc if not token.is_stop and token.is_alpha]\n",
    "\n",
    "# 상위 3개의 키워드 선택 (또는 원하는 수로 조정)\n",
    "top_keywords = keywords[:3]\n",
    "\n",
    "# 'KEYWORD' 변수에 키워드 저장\n",
    "KEYWORD = ', '.join(top_keywords)\n",
    "\n",
    "# 결과 출력\n",
    "print(KEYWORD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9264e18",
   "metadata": {},
   "source": [
    "(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f57fe317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타다가, Weverse, Con\n"
     ]
    }
   ],
   "source": [
    "# spaCy 모델 로드\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# 'SUMMARY_2' 변수에 있는 기사 요약문\n",
    "summary = news_hybe['SUMMARY_2'].iloc[2]\n",
    "\n",
    "# spaCy를 사용하여 문장을 처리하고 키워드 추출\n",
    "doc = nlp(summary)\n",
    "\n",
    "# 키워드 추출\n",
    "keywords = [token.text for token in doc if not token.is_stop and token.is_alpha]\n",
    "\n",
    "# 상위 3개의 키워드 선택 (또는 원하는 수로 조정)\n",
    "top_keywords = keywords[:3]\n",
    "\n",
    "# 'KEYWORD' 변수에 키워드 저장\n",
    "KEYWORD = ', '.join(top_keywords)\n",
    "\n",
    "# 결과 출력\n",
    "print(KEYWORD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5250d254",
   "metadata": {},
   "source": [
    "- 결론 : 그냥 문단 앞쪽에 위치한 명사 3개만 추출됨을 확인함. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bd7bd3",
   "metadata": {},
   "source": [
    "# Summa 모듈 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15287a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sm, 고, 대해 적대적\n"
     ]
    }
   ],
   "source": [
    "# spaCy 모델 로드\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# 'SUMMARY_2' 변수에 있는 기사 요약문\n",
    "summary = news_hybe['SUMMARY_2'].iloc[0]\n",
    "\n",
    "# spaCy를 사용하여 문장을 처리하고 토큰화\n",
    "doc = nlp(summary)\n",
    "\n",
    "# 문장에서 텍스트 추출\n",
    "text = \" \".join([token.text for token in doc])\n",
    "\n",
    "# TextRank를 사용하여 중요한 키워드 추출\n",
    "important_keywords = keywords.keywords(text)\n",
    "\n",
    "# 공백 문자를 기준으로 키워드를 분리\n",
    "top_keywords = important_keywords.split('\\n')\n",
    "\n",
    "# 상위 3개의 키워드 선택 (또는 원하는 수로 조정)\n",
    "top_keywords = top_keywords[:3]\n",
    "\n",
    "# 'KEYWORD' 변수에 키워드 저장\n",
    "KEYWORD = ', '.join(top_keywords)\n",
    "\n",
    "# 결과 출력\n",
    "print(KEYWORD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cbc0f1",
   "metadata": {},
   "source": [
    "- 역시나 성능이 좋지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca36c99",
   "metadata": {},
   "source": [
    "# koBERT 모듈 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab52e62",
   "metadata": {},
   "source": [
    "## 예시 1\n",
    "- 다음과 같은 기사 내용에 대한 keyword추출을 해보았다\n",
    "    - This is the first time that Chairman Bang's position has been made public through an overseas media interview since the joint statement he and former SM executive producer Lee Soo-man issued on the day of the acquisition announcement.After Chairman Bang announced that the acquisition of SM was not a hostile M&A, SM refuted the contents of his interview point by point. In its rebuttal, SM pointed out that -Bang is misrepresenting the meaning of hostile M&A -Bang said that hostile M&A is when a company is bought out of the market against the will of a majority or controlling shareholder, while hostile M&A is when a company's acquisition or merger is forced through without the consent of the board of directors, who are legally responsible for its management - and that hostile M&A usually takes the form of a tender offer or proxy contest, which is exactly what Hive is trying to do. On SM's side, -Chairman Bang said, 'In terms of trying to take over the industry, even if SM and Hive combined the volume of CDs sold in Korea, it would not be an absolute monopoly,‖ but the combination of the two companies would create a single monopolistic group of companies that would account for about 66 per cent of the total market revenue, and -a single company market monopoly would hinder the diversity and fair competition of K-pop and lead to a decline in industry competitiveness. In a direct refutation of Chairman Bang's position that he entered the SM takeover battle for the sake of K-pop's growth, SM added that -Hive is attempting a hostile takeover of SM in partnership with Lee Soo-man, who they say is responsible for SM's governance problems‖ and -We have serious concerns that if Hive's hostile takeover is successful, we will be forced to regress to a majority shareholder-only SM once again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7368343",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e57659dc044f7fa5bd961cba5cabef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)925a9/.gitattributes:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dde38bec60146afbca7c6a4b523d0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef61fe78e5ea43da8f2be6cf33c38d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)1a515925a9/README.md:   0%|          | 0.00/3.99k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d6b9717d0f4db8a8082cfde2bc31c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)515925a9/config.json:   0%|          | 0.00/550 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba8d651532d4d7e9515bb6f554dfa9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c708255a0f742caaeb54cfc3a4f5f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0a53c8a2774006ac1d9195a9f1a5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b70212847442f88d1c0b7f7e817a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05adf91022b4905a59b6e498c9ab695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)925a9/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf87c4a05c545d1909ac82021208cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/450 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f3e394c27041c8bf1043af10fe0641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)1a515925a9/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e897b3bde24300880490d905080547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)15925a9/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = \"\"\"\n",
    "\n",
    "This is the first time that Chairman Bang's position has been made public through an overseas media interview since the joint statement he and former SM executive producer Lee Soo-man issued on the day of the acquisition announcement.After Chairman Bang announced that the acquisition of SM was not a hostile M&A, SM refuted the contents of his interview point by point. In its rebuttal, SM pointed out that -Bang is misrepresenting the meaning of hostile M&A -Bang said that hostile M&A is when a company is bought out of the market against the will of a majority or controlling shareholder, while hostile M&A is when a company's acquisition or merger is forced through without the consent of the board of directors, who are legally responsible for its management - and that hostile M&A usually takes the form of a tender offer or proxy contest, which is exactly what Hive is trying to do. On SM's side, -Chairman Bang said, 'In terms of trying to take over the industry, even if SM and Hive combined the volume of CDs sold in Korea, it would not be an absolute monopoly,‖ but the combination of the two companies would create a single monopolistic group of companies that would account for about 66 per cent of the total market revenue, and -a single company market monopoly would hinder the diversity and fair competition of K-pop and lead to a decline in industry competitiveness. In a direct refutation of Chairman Bang's position that he entered the SM takeover battle for the sake of K-pop's growth, SM added that -Hive is attempting a hostile takeover of SM in partnership with Lee Soo-man, who they say is responsible for SM's governance problems‖ and -We have serious concerns that if Hive's hostile takeover is successful, we will be forced to regress to a majority shareholder-only SM once again.\n",
    "\n",
    "\"\"\"\n",
    "kw_model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "keywords = kw_model.extract_keywords(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "344687d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rebuttal', 0.154), ('battle', 0.1081), ('competition', 0.0888), ('interview', 0.0876), ('takeover', 0.0848)]\n"
     ]
    }
   ],
   "source": [
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5c985f",
   "metadata": {},
   "source": [
    "- **결과**\n",
    "- **spaCy, Summa보다 훨씬 잘 추출됨**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf3c98a",
   "metadata": {},
   "source": [
    "## 예시 2 \n",
    "- 다음과 같은 기사 내용에 대한 keyword추출을 해보았다\n",
    "    - 해외 언론 인터뷰를 통해 방 의장의 입장이 알려진 건 지분인수 발표 당일 이수만 전 SM 총괄 프로듀서와 함께 내놓은 공동성명 이후 처음이다.방 의장이 SM 인수에 대해 적대적 M&A가 아니라며 알리고 나서자 SM 측은 방 의장의 인터뷰 내용을 조목조목 반박했습니다.SM 측은 반박 자료를 통해 -방 의장이 적대적 M&A의 의미를 왜곡하고 있다-며 -방 의장은 적대적 M&A는 대주주 혹은 과점 주주의 의사에 반해서 회사를 시장에서 매집하는 것이라고 말했는데, 적대적 M&A는 경영에 대한 법적 책임을 지는 이사회 동의 없이 강행하는 기업의 인수와 합병을 의미한다-고 지적했습니다.이어 -또한 적대적 M&A는 통상 공개매수나 위임장 대결의 형태를 취하는데, 현재 하이브가 시도하는 적대적 M&A 활동과 정확히 일치한다-고 꼬집었습니다.SM 측은 -방 의장은 ‘업계를 다 가져가려고 한다라는 부분에 대해 SM과 하이브가 한국에서 파는 CD 물량을 다 합쳐도 절대적으로 독점이 되기는 어렵다’고 말했지만 양사 결합 시에는 전체 시장 매출의 약 66%를 차지하는 독과점적 단일 기업군이 탄생하게 된다-며 -단일 기업 시장 독과점은 K팝의 다양성과 공정 경쟁을 저해하고 산업 경쟁력 저하로 이어지게 된다-고 비판했습니다.K팝의 성장을 위해 SM 인수전에 뛰어들었다는 방 의장의 입장을 정면 반박한 겁니다.아울러 SM 측은 -하이브는 그들이 지적한 SM 지배구조문제의 원인 제공자인 이수만 전 총괄과 손잡고 SM에 대한 적대적 M&A를 시도하고 있다-며 -결국 하이브의 적대적 M&A가 성공할 경우 또 다시 대주주만을 위한 SM으로 퇴행할 수 밖에 없다는 심각한 우려를 가지고 있다-고 덧붙였습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dfc34ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"\n",
    "\n",
    "해외 언론 인터뷰를 통해 방 의장의 입장이 알려진 건 지분인수 발표 당일 이수만 전 SM 총괄 프로듀서와 함께 내놓은 공동성명 이후 처음이다.방 의장이 SM 인수에 대해 적대적 M&A가 아니라며 알리고 나서자 SM 측은 방 의장의 인터뷰 내용을 조목조목 반박했습니다.SM 측은 반박 자료를 통해 -방 의장이 적대적 M&A의 의미를 왜곡하고 있다-며 -방 의장은 적대적 M&A는 대주주 혹은 과점 주주의 의사에 반해서 회사를 시장에서 매집하는 것이라고 말했는데, 적대적 M&A는 경영에 대한 법적 책임을 지는 이사회 동의 없이 강행하는 기업의 인수와 합병을 의미한다-고 지적했습니다.이어 -또한 적대적 M&A는 통상 공개매수나 위임장 대결의 형태를 취하는데, 현재 하이브가 시도하는 적대적 M&A 활동과 정확히 일치한다-고 꼬집었습니다.SM 측은 -방 의장은 ‘업계를 다 가져가려고 한다라는 부분에 대해 SM과 하이브가 한국에서 파는 CD 물량을 다 합쳐도 절대적으로 독점이 되기는 어렵다’고 말했지만 양사 결합 시에는 전체 시장 매출의 약 66%를 차지하는 독과점적 단일 기업군이 탄생하게 된다-며 -단일 기업 시장 독과점은 K팝의 다양성과 공정 경쟁을 저해하고 산업 경쟁력 저하로 이어지게 된다-고 비판했습니다.K팝의 성장을 위해 SM 인수전에 뛰어들었다는 방 의장의 입장을 정면 반박한 겁니다.아울러 SM 측은 -하이브는 그들이 지적한 SM 지배구조문제의 원인 제공자인 이수만 전 총괄과 손잡고 SM에 대한 적대적 M&A를 시도하고 있다-며 -결국 하이브의 적대적 M&A가 성공할 경우 또 다시 대주주만을 위한 SM으로 퇴행할 수 밖에 없다는 심각한 우려를 가지고 있다-고 덧붙였습니다.\n",
    "\"\"\"\n",
    "kw_model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "keywords = kw_model.extract_keywords(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc48f642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('지배구조문제의', 0.8573), ('대주주만을', 0.8339), ('절대적으로', 0.8321), ('독과점은', 0.8157), ('매집하는', 0.8066)]\n"
     ]
    }
   ],
   "source": [
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2db4cfa",
   "metadata": {},
   "source": [
    "## 예시 3\n",
    "- 다음과 같은 기사 내용에 대한 keyword추출을 해보았다\n",
    "    - 올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를 기록할 것이라는 전망이 나오면서 엔터 관련 주들이 강세다.14일 마켓포인트에 따르면 오전 9시16분 현재 JYP Ent.는 전 거래일 대비 7.57% 오른 8만6800원에 거래되고 있다. 하이브는 3.47% 오른 25만3000원에 거래 중이고, 와이지엔터테인먼트와 에스엠도 각각 3.8%, 4.03% 오름세를 나타내고 있다.이는 최근 BTS 지민이 빌보드 싱글 차트 1위를 차지하고, 그룹 트와이스와 투모로우바이투게더가 빌보드 200차트에 머무는 등 글로벌 시장에서 K-pop이 약진을 하고 있기 때문인 것으로 풀이된다. 박성국 교보증권 연구원은 “엔터 4사의 올해 2분기 합산 앨범판매량과 콘서트 관객 수 모두 역대 최대 분기를 기록할 것으로 전망된다”라며 “주요 아티스트 컴백 몰리며 올해 2분기 엔터 4사 합산 앨범판매량 2210만장 기록할 것으로 예상된다”고 내다봤다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed5b3635",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"\n",
    "올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를 기록할 것이라는 전망이 나오면서 엔터 관련 주들이 강세다.14일 마켓포인트에 따르면 오전 9시16분 현재 JYP Ent.는 전 거래일 대비 7.57% 오른 8만6800원에 거래되고 있다. 하이브는 3.47% 오른 25만3000원에 거래 중이고, 와이지엔터테인먼트와 에스엠도 각각 3.8%, 4.03% 오름세를 나타내고 있다.이는 최근 BTS 지민이 빌보드 싱글 차트 1위를 차지하고, 그룹 트와이스와 투모로우바이투게더가 빌보드 200차트에 머무는 등 글로벌 시장에서 K-pop이 약진을 하고 있기 때문인 것으로 풀이된다. 박성국 교보증권 연구원은 “엔터 4사의 올해 2분기 합산 앨범판매량과 콘서트 관객 수 모두 역대 최대 분기를 기록할 것으로 전망된다”라며 “주요 아티스트 컴백 몰리며 올해 2분기 엔터 4사 합산 앨범판매량 2210만장 기록할 것으로 예상된다”고 내다봤다.\n",
    "\n",
    "\"\"\"\n",
    "kw_model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "keywords = kw_model.extract_keywords(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc174f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('투모로우바이투게더가', 0.8842), ('와이지엔터테인먼트와', 0.8396), ('엔터주들의', 0.7949), ('교보증권', 0.7812), ('차지하고', 0.7549)]\n"
     ]
    }
   ],
   "source": [
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5c951ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'그룹 방탄소년단(BTS)과 세븐틴 등이 소속된 대형 연예기rn획사 하이브는 인공지능(AI) 오디오 기업 수퍼톤을 인수했다고 31일 밝혔습니다.\\nrn 수퍼톤은 목소리를 구성하는 다양한 요소를 조합해 무한에 가까운 목소리를 생성하는 AI rn오디오 기술을 보유한 기업입니다.\\nrnn 이교구 수퍼톤 대표는 \"수퍼톤의 AI 오디오 기술은 기획 단계에서부터 제작, 편집, 후처리rn, 배급, 유통 등 콘텐츠 제작의 모든 단계에 적용할 수 있다\"며 \"음악 콘텐츠 영역에서 시작해rn 점차 인지도를 넓혀 이제는 영화, 애니메이션, 오디오북, 게임 등의 분야에서도 가치를 안정 rn받고 있다\"고 소개했습니다.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_hybe['SUMMARY_2'].iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f58cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = news_hybe['SUMMARY_2'].iloc[10]\n",
    "kw_model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "keywords = kw_model.extract_keywords(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0135e1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('방탄소년단', 0.8162), ('기업입니다', 0.7676), ('생성하는', 0.7391), ('하이브는', 0.7383), ('인공지능', 0.7308)]\n"
     ]
    }
   ],
   "source": [
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bfb64ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수출액 3000억원 육박ㆍ판매량 8000만장 또 한 번 역사를 썼습니다.\n",
      "한국음악콘텐츠협회가 운영하는 대중음악 음반, 음원 집계 차트인 써클차트에 따르면 지난해 1월부터 12월까지 월간 톱400에 올라온 음반의 국내외 합산 판매량은 8074만 4916만 장으로 기록됐습니다.\n",
      "전년 대비 약 2140만 장 증가했습니다.\n",
      "[('3000억원', 0.7204), ('8000만장', 0.7106), ('써클차트에', 0.7093), ('대중음악', 0.7085), ('운영하는', 0.6944)]\n"
     ]
    }
   ],
   "source": [
    "a = news_hybe['SUMMARY_2'].iloc[40]\n",
    "print(a)\n",
    "doc = a\n",
    "kw_model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "keywords = kw_model.extract_keywords(doc)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f71efc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "올해부터 방탄소년단(BTS)이 그룹 활동을 중단하지만 BTS 소속사 하이브는 여전히 '엔터주 톱픽'이라는 분석이 나왔습니다.\n",
      "올해 BTS 멤버 3인의 솔로 앨범도 각각 100만 장 안팎의 판매액을 올릴 것으로 예측됐다.IBK투자증권은 BTS 매출에 직접적으로 기여하는 코어 팬덤(충성도 높은 팬)을 70만 명으로 추산했습니다.\n",
      "세븐틴은 32만 명, 투모로우바이투게더 25만 명, 엔하이픈 16만 명으로 K팝 그룹 중에선 최상위권입니다.\n",
      "[('투모로우바이투게더', 0.8259), ('방탄소년단', 0.8024), ('중단하지만', 0.7781), ('ibk투자증권은', 0.7645), ('직접적으로', 0.7551)]\n"
     ]
    }
   ],
   "source": [
    "a = news_hybe['SUMMARY_2'].iloc[100]\n",
    "print(a)\n",
    "doc = a\n",
    "kw_model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "keywords = kw_model.extract_keywords(doc)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5773cb04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['투모로우바이투게더', '방탄소년단', '중단하지만', 'ibk투자증권은', '직접적으로']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_list = []\n",
    "for kw in keywords:\n",
    "    tmp_list.append(kw[0])\n",
    "tmp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae8204",
   "metadata": {},
   "source": [
    "# 키워드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "918f1fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필터링 하고자 하는 키워드 리스트 생성\n",
    "event_kw = ['컴백', '데뷔', '신곡','신인', '콘서트', '매진', '페스티벌', '축제', '발매' ,'합병','인수']\n",
    "hybe_kw =  ['하이브','hybe','방시혁','뉴진스','new jeans','newjeans','민지','해린','혜인','다니엘','하니',\n",
    "            '민희진','방탄소년단','bts','전정국','제이홉','rm','슈가','정국',\n",
    "            '르세라핌','le sserafim','채원','카즈하','은채','사쿠라','허윤진',\n",
    "            '세븐틴','seventeen','투모로우바이투게더', 'txt','프로미스나인','fromis 9','fromis9',\n",
    "            '나나','nana','이현','lee hyun','미드낫','midnatt','엔하이픈','enhypen',\n",
    "            '백호','강동호','황민현','예하나','성연','지코','zico','앤팀','&team','히라테 유리나',\n",
    "            '보이넥스트도어','boynextdoor','boy next door','위버스','부석순']\n",
    "sm_kw = ['sm','에스엠','이수만','boa','에스파','aespa','카리나','윈터','지젤','닝닝',\n",
    "         '엑소','exo','샤이니','shinee','엔시티','nct',\n",
    "         '동방신기','tvxq','슈퍼주니어','super junior','superjunior','소녀시대',\n",
    "         '레드벨벳','red velvet','redvelvet','웨이션브이','슈퍼엠','superm','super m',\n",
    "         '갓더비트','갓 더 비트','got the beat','라이즈','riize','디어유']\n",
    "yg_kw = ['와이지','yg','양현석','블랙핑크','blackpink','black pink','제니','리사','지수','로제',\n",
    "         '트레저','treasure','악뮤','악동뮤지션','akmu','위너','winnter','지디','GD','권지용','지드래곤',\n",
    "         '젝스키스','sechskies','sechs kies','베이비몬스터','베이비 몬스터','babymonster','baby monster']\n",
    "jyp_kw = ['제이와이피','jyp','박진영','스트레이키즈','스트레이 키즈','straykids','stray kids',\n",
    "          '트와이스','twice','엔믹스','nmixx', '데이식스','day6','day 6',\n",
    "          '있지','잇지','itzy','채령','유나','류진','리아','예지',\n",
    "          '투피엠','2pm','2 pm','보이스토리','boystory','boy story',\n",
    "          '야오천','yaochen','니지유','niziu','엑스디너리 히어로즈','xdinary heroes','xdinaryheroes']\n",
    "filtering_list = event_kw + hybe_kw + sm_kw + yg_kw + jyp_kw "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce5d6fb",
   "metadata": {},
   "source": [
    "# 함수생성을 위한 임시 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55e3ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_hybe_copy = news_hybe.copy()\n",
    "news_sm_copy = news_sm.copy()\n",
    "news_yg_copy = news_yg.copy()\n",
    "news_jyp_copy = news_jyp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9fe555c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_hybe_copy = news_hybe.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f8fc8",
   "metadata": {},
   "source": [
    "- news_hybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d5f6da9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 키워드 추출을 위한 모델을 초기화한다.\n",
    "kw_model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "\n",
    "# 데이터프레임에 새로운 열을 추가하여 키워드를 저장할 준비를 한다.\n",
    "news_hybe_copy['KEYWORDS'] = ''\n",
    "\n",
    "# 각 뉴스 기사에 대해 키워드 추출 및 필터링을 수행한다.\n",
    "for idx, row in news_hybe_copy.iterrows():\n",
    "    doc = row['SUMMARY_2']\n",
    "    \n",
    "    # 키워드 추출\n",
    "    keywords = kw_model.extract_keywords(doc) # keywords = keyBERT 로 추출한 키워드\n",
    "    \n",
    "    \n",
    "    # 필터링된 키워드를 저장할 변수를 초기화한다.\n",
    "    filtered_keywords_list = []\n",
    "    \n",
    "    # 필터링을 수행한다.\n",
    "    for kw in keywords:\n",
    "        for f_keyword in filtering_list: # filtering_list = 포함될 경우 추출할 키워드 모아둔 리스트 \n",
    "            if f_keyword in kw[0]:\n",
    "                filtered_keywords_list.append(f_keyword)\n",
    "    \n",
    "    # 필터링된 키워드를 데이터프레임에 저장한다.\n",
    "    news_hybe_copy.at[idx, 'KEYWORDS'] = ', '.join(filtered_keywords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "64e3cb46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NEWS_YM</th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>WRITER</th>\n",
       "      <th>SUBCATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>IMPORTANCE</th>\n",
       "      <th>ITEM_NAME</th>\n",
       "      <th>TAG_LIST</th>\n",
       "      <th>PARSED CONTENT</th>\n",
       "      <th>LENGTH_SUM</th>\n",
       "      <th>SUMMARY</th>\n",
       "      <th>SUMMARY_2</th>\n",
       "      <th>SENTIMENT_NEGATIVE</th>\n",
       "      <th>SENTIMENT_NEUTRAL</th>\n",
       "      <th>SENTIMENT_POSITIVE</th>\n",
       "      <th>DATE_NEW</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>KEYWORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202303</td>\n",
       "      <td>2023-03-03 13:40:44</td>\n",
       "      <td>매일경제</td>\n",
       "      <td>기술</td>\n",
       "      <td>하이브의 SM 인수, '적대적 M&amp;A' 성격 두고 방시혁·SM 충돌</td>\n",
       "      <td>29.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>의사| 독점</td>\n",
       "      <td>방시혁 하이브 의장이 미국 CNN 방송에 출연해 SM엔터테인먼트 인수전을 적대적 M...</td>\n",
       "      <td>2326</td>\n",
       "      <td>해외 언론 인터뷰를 통해 방 의장의 입장이 알려진 건 지난 2월 10일 지분인수 발...</td>\n",
       "      <td>해외 언론 인터뷰를 통해 방 의장의 입장이 알려진 건 지분인수 발표 당일 이수만 전...</td>\n",
       "      <td>95.182945</td>\n",
       "      <td>4.809798</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>2023-03-03</td>\n",
       "      <td>금</td>\n",
       "      <td>-95.175687</td>\n",
       "      <td>HYBE</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NEWS_YM           DATE_TIME WRITER SUBCATEGORY  \\\n",
       "0   202303 2023-03-03 13:40:44   매일경제          기술   \n",
       "\n",
       "                                   TITLE  IMPORTANCE ITEM_NAME TAG_LIST  \\\n",
       "0  하이브의 SM 인수, '적대적 M&A' 성격 두고 방시혁·SM 충돌       29.27       NaN   의사| 독점   \n",
       "\n",
       "                                      PARSED CONTENT  LENGTH_SUM  \\\n",
       "0  방시혁 하이브 의장이 미국 CNN 방송에 출연해 SM엔터테인먼트 인수전을 적대적 M...        2326   \n",
       "\n",
       "                                             SUMMARY  \\\n",
       "0  해외 언론 인터뷰를 통해 방 의장의 입장이 알려진 건 지난 2월 10일 지분인수 발...   \n",
       "\n",
       "                                           SUMMARY_2  SENTIMENT_NEGATIVE  \\\n",
       "0  해외 언론 인터뷰를 통해 방 의장의 입장이 알려진 건 지분인수 발표 당일 이수만 전...           95.182945   \n",
       "\n",
       "   SENTIMENT_NEUTRAL  SENTIMENT_POSITIVE   DATE_NEW DAY  SENTIMENT COMPANY  \\\n",
       "0           4.809798            0.007258 2023-03-03   금 -95.175687    HYBE   \n",
       "\n",
       "  KEYWORDS  \n",
       "0           "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_hybe_copy.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e475e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 추출을 위한 모델을 초기화한다.\n",
    "kw_model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "\n",
    "# 데이터프레임에 새로운 열을 추가하여 키워드를 저장할 준비를 한다.\n",
    "news_sm_copy['KEYWORDS'] = ''\n",
    "\n",
    "# 각 뉴스 기사에 대해 키워드 추출 및 필터링을 수행한다.\n",
    "for idx, row in news_sm_copy.iterrows():\n",
    "    doc = row['SUMMARY_2']\n",
    "    \n",
    "    # 키워드 추출\n",
    "    keywords = kw_model.extract_keywords(doc) # keywords = keyBERT 로 추출한 키워드\n",
    "    \n",
    "    \n",
    "    # 필터링된 키워드를 저장할 변수를 초기화한다.\n",
    "    filtered_keywords_list = []\n",
    "    \n",
    "    # 필터링을 수행한다.\n",
    "    for kw in keywords:\n",
    "        for f_keyword in filtering_list: # filtering_list = 포함될 경우 추출할 키워드 모아둔 리스트 \n",
    "            if f_keyword in kw[0]:\n",
    "                filtered_keywords_list.append(f_keyword)\n",
    "    \n",
    "    # 필터링된 키워드를 데이터프레임에 저장한다.\n",
    "    news_sm_copy.at[idx, 'KEYWORDS'] = ', '.join(filtered_keywords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "539771b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NEWS_YM</th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>WRITER</th>\n",
       "      <th>SUBCATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>IMPORTANCE</th>\n",
       "      <th>ITEM_NAME</th>\n",
       "      <th>TAG_LIST</th>\n",
       "      <th>PARSED CONTENT</th>\n",
       "      <th>LENGTH_SUM</th>\n",
       "      <th>SUMMARY</th>\n",
       "      <th>SUMMARY_2</th>\n",
       "      <th>SENTIMENT_NEGATIVE</th>\n",
       "      <th>SENTIMENT_NEUTRAL</th>\n",
       "      <th>SENTIMENT_POSITIVE</th>\n",
       "      <th>DATE_NEW</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>KEYWORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202304</td>\n",
       "      <td>2023-04-14 09:22:37</td>\n",
       "      <td>eDaily</td>\n",
       "      <td>경제</td>\n",
       "      <td>[특징주]엔터株, K-팝 약진 속 일제히 강세</td>\n",
       "      <td>27.41</td>\n",
       "      <td>JYP Ent.|하이브|와이지엔터테인먼트|에스엠</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[이데일리 이용성 기자] 올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객...</td>\n",
       "      <td>2332</td>\n",
       "      <td>올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를...</td>\n",
       "      <td>올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를...</td>\n",
       "      <td>0.024469</td>\n",
       "      <td>0.03598</td>\n",
       "      <td>99.93955</td>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>금</td>\n",
       "      <td>99.915081</td>\n",
       "      <td>ALL</td>\n",
       "      <td>투모로우바이투게더, 와이지</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NEWS_YM           DATE_TIME  WRITER SUBCATEGORY                      TITLE  \\\n",
       "0   202304 2023-04-14 09:22:37  eDaily          경제  [특징주]엔터株, K-팝 약진 속 일제히 강세   \n",
       "\n",
       "   IMPORTANCE                   ITEM_NAME TAG_LIST  \\\n",
       "0       27.41  JYP Ent.|하이브|와이지엔터테인먼트|에스엠      NaN   \n",
       "\n",
       "                                      PARSED CONTENT  LENGTH_SUM  \\\n",
       "0  [이데일리 이용성 기자] 올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객...        2332   \n",
       "\n",
       "                                             SUMMARY  \\\n",
       "0  올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를...   \n",
       "\n",
       "                                           SUMMARY_2  SENTIMENT_NEGATIVE  \\\n",
       "0  올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를...            0.024469   \n",
       "\n",
       "   SENTIMENT_NEUTRAL  SENTIMENT_POSITIVE   DATE_NEW DAY  SENTIMENT COMPANY  \\\n",
       "0            0.03598            99.93955 2023-04-14   금  99.915081     ALL   \n",
       "\n",
       "         KEYWORDS  \n",
       "0  투모로우바이투게더, 와이지  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_sm_copy.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cdbb71bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 추출을 위한 모델을 초기화한다.\n",
    "kw_model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "\n",
    "# 데이터프레임에 새로운 열을 추가하여 키워드를 저장할 준비를 한다.\n",
    "news_yg_copy['KEYWORDS'] = ''\n",
    "\n",
    "# 각 뉴스 기사에 대해 키워드 추출 및 필터링을 수행한다.\n",
    "for idx, row in news_yg_copy.iterrows():\n",
    "    doc = row['SUMMARY_2']\n",
    "    \n",
    "    # 키워드 추출\n",
    "    keywords = kw_model.extract_keywords(doc) # keywords = keyBERT 로 추출한 키워드\n",
    "    \n",
    "    \n",
    "    # 필터링된 키워드를 저장할 변수를 초기화한다.\n",
    "    filtered_keywords_list = []\n",
    "    \n",
    "    # 필터링을 수행한다.\n",
    "    for kw in keywords:\n",
    "        for f_keyword in filtering_list: # filtering_list = 포함될 경우 추출할 키워드 모아둔 리스트 \n",
    "            if f_keyword in kw[0]:\n",
    "                filtered_keywords_list.append(f_keyword)\n",
    "    \n",
    "    # 필터링된 키워드를 데이터프레임에 저장한다.\n",
    "    news_yg_copy.at[idx, 'KEYWORDS'] = ', '.join(filtered_keywords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c9d6cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NEWS_YM</th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>WRITER</th>\n",
       "      <th>SUBCATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>IMPORTANCE</th>\n",
       "      <th>ITEM_NAME</th>\n",
       "      <th>TAG_LIST</th>\n",
       "      <th>PARSED CONTENT</th>\n",
       "      <th>LENGTH_SUM</th>\n",
       "      <th>SUMMARY</th>\n",
       "      <th>SUMMARY_2</th>\n",
       "      <th>SENTIMENT_NEGATIVE</th>\n",
       "      <th>SENTIMENT_NEUTRAL</th>\n",
       "      <th>SENTIMENT_POSITIVE</th>\n",
       "      <th>DATE_NEW</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>KEYWORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202304</td>\n",
       "      <td>2023-04-14 09:22:37</td>\n",
       "      <td>eDaily</td>\n",
       "      <td>경제</td>\n",
       "      <td>[특징주]엔터株, K-팝 약진 속 일제히 강세</td>\n",
       "      <td>27.41</td>\n",
       "      <td>JYP Ent.|하이브|와이지엔터테인먼트|에스엠</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[이데일리 이용성 기자] 올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객...</td>\n",
       "      <td>2332</td>\n",
       "      <td>올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를...</td>\n",
       "      <td>올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를...</td>\n",
       "      <td>0.024469</td>\n",
       "      <td>0.03598</td>\n",
       "      <td>99.93955</td>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>금</td>\n",
       "      <td>99.915081</td>\n",
       "      <td>ALL</td>\n",
       "      <td>투모로우바이투게더, 와이지</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NEWS_YM           DATE_TIME  WRITER SUBCATEGORY                      TITLE  \\\n",
       "0   202304 2023-04-14 09:22:37  eDaily          경제  [특징주]엔터株, K-팝 약진 속 일제히 강세   \n",
       "\n",
       "   IMPORTANCE                   ITEM_NAME TAG_LIST  \\\n",
       "0       27.41  JYP Ent.|하이브|와이지엔터테인먼트|에스엠      NaN   \n",
       "\n",
       "                                      PARSED CONTENT  LENGTH_SUM  \\\n",
       "0  [이데일리 이용성 기자] 올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객...        2332   \n",
       "\n",
       "                                             SUMMARY  \\\n",
       "0  올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를...   \n",
       "\n",
       "                                           SUMMARY_2  SENTIMENT_NEGATIVE  \\\n",
       "0  올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를...            0.024469   \n",
       "\n",
       "   SENTIMENT_NEUTRAL  SENTIMENT_POSITIVE   DATE_NEW DAY  SENTIMENT COMPANY  \\\n",
       "0            0.03598            99.93955 2023-04-14   금  99.915081     ALL   \n",
       "\n",
       "         KEYWORDS  \n",
       "0  투모로우바이투게더, 와이지  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_yg_copy.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c431f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 추출을 위한 모델을 초기화한다.\n",
    "kw_model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "\n",
    "# 데이터프레임에 새로운 열을 추가하여 키워드를 저장할 준비를 한다.\n",
    "news_jyp_copy['KEYWORDS'] = ''\n",
    "\n",
    "# 각 뉴스 기사에 대해 키워드 추출 및 필터링을 수행한다.\n",
    "for idx, row in news_jyp_copy.iterrows():\n",
    "    doc = row['SUMMARY_2']\n",
    "    \n",
    "# 키워드 추출\n",
    "    keywords = kw_model.extract_keywords(doc) # keywords = keyBERT 로 추출한 키워드\n",
    "    \n",
    "    \n",
    "    # 필터링된 키워드를 저장할 변수를 초기화한다.\n",
    "    filtered_keywords_list = []\n",
    "    \n",
    "    # 필터링을 수행한다.\n",
    "    for kw in keywords:\n",
    "        for f_keyword in filtering_list: # filtering_list = 포함될 경우 추출할 키워드 모아둔 리스트 \n",
    "            if f_keyword in kw[0]:\n",
    "                filtered_keywords_list.append(f_keyword)\n",
    "    \n",
    "    # 필터링된 키워드를 데이터프레임에 저장한다.\n",
    "    news_jyp_copy.at[idx, 'KEYWORDS'] = ', '.join(filtered_keywords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cb219429",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NEWS_YM</th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>WRITER</th>\n",
       "      <th>SUBCATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>IMPORTANCE</th>\n",
       "      <th>ITEM_NAME</th>\n",
       "      <th>TAG_LIST</th>\n",
       "      <th>PARSED CONTENT</th>\n",
       "      <th>LENGTH_SUM</th>\n",
       "      <th>SUMMARY</th>\n",
       "      <th>SUMMARY_2</th>\n",
       "      <th>SENTIMENT_NEGATIVE</th>\n",
       "      <th>SENTIMENT_NEUTRAL</th>\n",
       "      <th>SENTIMENT_POSITIVE</th>\n",
       "      <th>DATE_NEW</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>KEYWORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202304</td>\n",
       "      <td>2023-04-14 09:22:37</td>\n",
       "      <td>eDaily</td>\n",
       "      <td>경제</td>\n",
       "      <td>[특징주]엔터株, K-팝 약진 속 일제히 강세</td>\n",
       "      <td>27.41</td>\n",
       "      <td>JYP Ent.|하이브|와이지엔터테인먼트|에스엠</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[이데일리 이용성 기자] 올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객...</td>\n",
       "      <td>2332</td>\n",
       "      <td>올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를...</td>\n",
       "      <td>올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를...</td>\n",
       "      <td>0.024469</td>\n",
       "      <td>0.03598</td>\n",
       "      <td>99.93955</td>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>금</td>\n",
       "      <td>99.915081</td>\n",
       "      <td>ALL</td>\n",
       "      <td>투모로우바이투게더, 와이지</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NEWS_YM           DATE_TIME  WRITER SUBCATEGORY                      TITLE  \\\n",
       "0   202304 2023-04-14 09:22:37  eDaily          경제  [특징주]엔터株, K-팝 약진 속 일제히 강세   \n",
       "\n",
       "   IMPORTANCE                   ITEM_NAME TAG_LIST  \\\n",
       "0       27.41  JYP Ent.|하이브|와이지엔터테인먼트|에스엠      NaN   \n",
       "\n",
       "                                      PARSED CONTENT  LENGTH_SUM  \\\n",
       "0  [이데일리 이용성 기자] 올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객...        2332   \n",
       "\n",
       "                                             SUMMARY  \\\n",
       "0  올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를...   \n",
       "\n",
       "                                           SUMMARY_2  SENTIMENT_NEGATIVE  \\\n",
       "0  올해 2분기 국내 엔터주들의 합산 앨범판매량과 콘서트 관객수 모두 역대 최대 분기를...            0.024469   \n",
       "\n",
       "   SENTIMENT_NEUTRAL  SENTIMENT_POSITIVE   DATE_NEW DAY  SENTIMENT COMPANY  \\\n",
       "0            0.03598            99.93955 2023-04-14   금  99.915081     ALL   \n",
       "\n",
       "         KEYWORDS  \n",
       "0  투모로우바이투게더, 와이지  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_jyp_copy.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "35908507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복사본으로 백업\n",
    "news_hybe_keybert = news_hybe_copy.copy()\n",
    "news_sm_keybert = news_sm_copy.copy()\n",
    "news_yg_keybert = news_yg_copy.copy()\n",
    "news_jyp_keybert = news_jyp_copy.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc39f65",
   "metadata": {},
   "source": [
    "# 날짜별로 정리, 중복/빈 키워드 삭제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "44ecd497",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_hybe_keybert = news_hybe_keybert[['DATE_NEW','KEYWORDS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fbc3df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_sm_keybert = news_sm_keybert[['DATE_NEW','KEYWORDS']]\n",
    "news_yg_keybert = news_yg_keybert[['DATE_NEW','KEYWORDS']]\n",
    "news_jyp_keybert = news_jyp_keybert[['DATE_NEW','KEYWORDS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "34342b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DATE_NEW                                           KEYWORDS\n",
      "0   2023-01-02                방탄소년단, 방탄소년단, 블랙핑크,소녀시대,르세라핌, 방탄소년단\n",
      "1   2023-01-03   하이브,방탄소년단,투모로우바이투게더, , 지수, 방탄소년단,콘서트,투모로우바이투게더, \n",
      "2   2023-01-04            방탄소년단, , 뉴진스, yg, 하이브,르세라핌, 뉴진스, , , yg\n",
      "3   2023-01-05  와이지,jyp, 방탄소년단,뉴진스, 방탄소년단,투모로우바이투게더, , 블랙핑크,베이...\n",
      "4   2023-01-06                   방탄소년단, , 방탄소년단,투모로우바이투게더, , , , \n",
      "..         ...                                                ...\n",
      "121 2023-06-20  방탄소년단,블랙핑크,박진영,프로미스나인, 방탄소년단,콘서트, 방탄소년단, 콘서트, ...\n",
      "122 2023-06-21                                          투모로우바이투게더\n",
      "123 2023-06-22  방탄소년단,블랙핑크, 방탄소년단, 지코,리아, , 방탄소년단,뉴진스,르세라핌, 지코...\n",
      "124 2023-06-23                        방탄소년단,뉴진스, 와이지, 하이브, , 트와이스\n",
      "125 2023-06-26             , , 리사, , 동방신기, 하이브,방탄소년단, , , 콘서트, , \n",
      "\n",
      "[126 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 'KEYWORDS' 열의 문자열을 분리하고 중복을 제거하여 리스트로 만들기\n",
    "news_hybe_keybert['KEYWORDS'] = news_hybe_keybert['KEYWORDS'].apply(lambda x: list(set(x.split(', '))))\n",
    "\n",
    "# 'KEYWORDS' 열의 리스트를 문자열로 변환 후, 같은 'DATE_NEW' 값을 가지는 행들을 그룹화하고 'KEYWORDS' 리스트 합치기\n",
    "news_hybe_keybert = news_hybe_keybert.groupby('DATE_NEW')['KEYWORDS'].agg(lambda x: ', '.join(','.join(sublist) for sublist in x)).reset_index()\n",
    "\n",
    "# 결과 출력\n",
    "print(news_hybe_keybert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c48d93ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소녀시대, 르세라핌,  블랙핑크, 방탄소년단,  방탄소년단\n"
     ]
    }
   ],
   "source": [
    "# 'KEYWORDS' 열에서 빈 문자열 및 중복된 항목 제거\n",
    "news_hybe_keybert['KEYWORDS'] = news_hybe_keybert['KEYWORDS'].str.split(',').apply(lambda x: ', '.join(filter(None, set(x))))\n",
    "\n",
    "# 결과 출력\n",
    "print(news_hybe_keybert['KEYWORDS'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7cbf6198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "블랙핑크, 소녀시대, 르세라핌,  sm\n"
     ]
    }
   ],
   "source": [
    "# 'KEYWORDS' 열의 문자열을 분리하고 중복을 제거하여 리스트로 만들기\n",
    "news_sm_keybert['KEYWORDS'] = news_sm_keybert['KEYWORDS'].apply(lambda x: list(set(x.split(', '))))\n",
    "\n",
    "# 'KEYWORDS' 열의 리스트를 문자열로 변환 후, 같은 'DATE_NEW' 값을 가지는 행들을 그룹화하고 'KEYWORDS' 리스트 합치기\n",
    "news_sm_keybert = news_sm_keybert.groupby('DATE_NEW')['KEYWORDS'].agg(lambda x: ', '.join(','.join(sublist) for sublist in x)).reset_index()\n",
    "\n",
    "# 'KEYWORDS' 열에서 빈 문자열 및 중복된 항목 제거\n",
    "news_sm_keybert['KEYWORDS'] = news_sm_keybert['KEYWORDS'].str.split(',').apply(lambda x: ', '.join(filter(None, set(x))))\n",
    "\n",
    "# 결과 출력\n",
    "print(news_sm_keybert['KEYWORDS'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c3d95d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "와이지, 블랙핑크, 베이비몬스터, 트와이스,  와이지, 소녀시대,  베이비몬스터, 르세라핌,  yg, yg,  블랙핑크,  방탄소년단\n"
     ]
    }
   ],
   "source": [
    "# 'KEYWORDS' 열의 문자열을 분리하고 중복을 제거하여 리스트로 만들기\n",
    "news_yg_keybert['KEYWORDS'] = news_yg_keybert['KEYWORDS'].apply(lambda x: list(set(x.split(', '))))\n",
    "\n",
    "# 'KEYWORDS' 열의 리스트를 문자열로 변환 후, 같은 'DATE_NEW' 값을 가지는 행들을 그룹화하고 'KEYWORDS' 리스트 합치기\n",
    "news_yg_keybert = news_yg_keybert.groupby('DATE_NEW')['KEYWORDS'].agg(lambda x: ', '.join(','.join(sublist) for sublist in x)).reset_index()\n",
    "\n",
    "# 'KEYWORDS' 열에서 빈 문자열 및 중복된 항목 제거\n",
    "news_yg_keybert['KEYWORDS'] = news_yg_keybert['KEYWORDS'].str.split(',').apply(lambda x: ', '.join(filter(None, set(x))))\n",
    "\n",
    "# 결과 출력\n",
    "print(news_yg_keybert['KEYWORDS'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bdfc19d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "블랙핑크, 소녀시대, 르세라핌\n"
     ]
    }
   ],
   "source": [
    "# 'KEYWORDS' 열의 문자열을 분리하고 중복을 제거하여 리스트로 만들기\n",
    "news_jyp_keybert['KEYWORDS'] = news_jyp_keybert['KEYWORDS'].apply(lambda x: list(set(x.split(', '))))\n",
    "\n",
    "# 'KEYWORDS' 열의 리스트를 문자열로 변환 후, 같은 'DATE_NEW' 값을 가지는 행들을 그룹화하고 'KEYWORDS' 리스트 합치기\n",
    "news_jyp_keybert = news_jyp_keybert.groupby('DATE_NEW')['KEYWORDS'].agg(lambda x: ', '.join(','.join(sublist) for sublist in x)).reset_index()\n",
    "\n",
    "# 'KEYWORDS' 열에서 빈 문자열 및 중복된 항목 제거\n",
    "news_jyp_keybert['KEYWORDS'] = news_jyp_keybert['KEYWORDS'].str.split(',').apply(lambda x: ', '.join(filter(None, set(x))))\n",
    "\n",
    "# 결과 출력\n",
    "print(news_jyp_keybert['KEYWORDS'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8ef1a9",
   "metadata": {},
   "source": [
    "# 소속사별로 추가적인 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9856e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복사본으로 백업\n",
    "news_hybe_cleaned = news_hybe_keybert.copy()\n",
    "news_sm_cleaned = news_sm_keybert.copy()\n",
    "news_yg_cleaned = news_yg_keybert.copy()\n",
    "news_jyp_cleaned = news_jyp_keybert.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2e3edd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_hybe_cleaned의 KEYWORDS 변수에서 다음 단어들만 다시 선택 \n",
    "event_kw = ['컴백', '데뷔', '신곡','신인', '콘서트', '매진', '페스티벌', '축제', '발매' ,'합병','인수']\n",
    "hybe_kw =  ['방시혁','뉴진스','new jeans','newjeans','민지','해린','혜인','다니엘','하니',\n",
    "            '민희진','방탄소년단','bts','전정국','제이홉','rm','슈가','정국',\n",
    "            '르세라핌','le sserafim','채원','카즈하','은채','사쿠라','허윤진',\n",
    "            '세븐틴','seventeen','투모로우바이투게더', 'txt','프로미스나인','fromis 9','fromis9',\n",
    "            '나나','nana','이현','lee hyun','미드낫','midnatt','엔하이픈','enhypen',\n",
    "            '백호','강동호','황민현','예하나','성연','지코','zico','앤팀','&team','히라테 유리나',\n",
    "            '보이넥스트도어','boynextdoor','boy next door','위버스','부석순']\n",
    "hybe_2nd_kw = event_kw + hybe_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0f5bdea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_sm_cleaned의 KEYWORDS 변수에서 다음 단어들만 다시 선택 \n",
    "event_kw = ['컴백', '데뷔', '신곡','신인', '콘서트', '매진', '페스티벌', '축제', '발매' ,'합병','인수']\n",
    "\n",
    "sm_kw = ['이수만','boa','에스파','aespa','카리나','윈터','지젤','닝닝',\n",
    "         '엑소','exo','샤이니','shinee','엔시티','nct',\n",
    "         '동방신기','tvxq','슈퍼주니어','super junior','superjunior','소녀시대',\n",
    "         '레드벨벳','red velvet','redvelvet','웨이션브이','슈퍼엠','superm','super m',\n",
    "         '갓더비트','갓 더 비트','got the beat','라이즈','riize','디어유']\n",
    "sm_2nd_kw = event_kw + sm_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "422a2f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_yg_cleaned의 KEYWORDS 변수에서 다음 단어들만 다시 선택 \n",
    "event_kw = ['컴백', '데뷔', '신곡','신인', '콘서트', '매진', '페스티벌', '축제', '발매' ,'합병','인수']\n",
    "\n",
    "yg_kw = ['양현석','블랙핑크','blackpink','black pink','제니','리사','지수','로제',\n",
    "         '트레저','treasure','악뮤','악동뮤지션','akmu','위너','winnter','지디','GD','권지용','지드래곤',\n",
    "         '젝스키스','sechskies','sechs kies','베이비몬스터','베이비 몬스터','babymonster','baby monster']\n",
    "\n",
    "yg_2nd_kw = event_kw + yg_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d31654db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_jyp_cleaned의 KEYWORDS 변수에서 다음 단어들만 다시 선택 \n",
    "event_kw = ['컴백', '데뷔', '신곡','신인', '콘서트', '매진', '페스티벌', '축제', '발매' ,'합병','인수']\n",
    "jyp_kw = ['스트레이키즈','스트레이 키즈','straykids','stray kids',\n",
    "          '트와이스','twice','엔믹스','nmixx', '데이식스','day6','day 6',\n",
    "          '있지','잇지','itzy','채령','유나','류진','리아','예지',\n",
    "          '투피엠','2pm','2 pm','보이스토리','boystory','boy story',\n",
    "          '야오천','yaochen','니지유','niziu','엑스디너리 히어로즈','xdinary heroes','xdinaryheroes']\n",
    "jyp_2nd_kw = event_kw + jyp_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5ae5ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'KEYWORDS' 열을 쉼표로 분리하고 필터링할 키워드만 남기기\n",
    "news_hybe_cleaned['KEYWORDS'] = news_hybe_cleaned['KEYWORDS'].str.split(', ').apply(lambda x: ', '.join([kw for kw in x if kw in hybe_2nd_kw]))\n",
    "\n",
    "news_sm_cleaned['KEYWORDS'] = news_sm_cleaned['KEYWORDS'].str.split(', ').apply(lambda x: ', '.join([kw for kw in x if kw in sm_2nd_kw]))\n",
    "\n",
    "news_yg_cleaned['KEYWORDS'] = news_yg_cleaned['KEYWORDS'].str.split(', ').apply(lambda x: ', '.join([kw for kw in x if kw in yg_2nd_kw]))\n",
    "\n",
    "news_jyp_cleaned['KEYWORDS'] = news_jyp_cleaned['KEYWORDS'].str.split(', ').apply(lambda x: ', '.join([kw for kw in x if kw in jyp_2nd_kw]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9dcce3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_NEW</th>\n",
       "      <th>KEYWORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>르세라핌, 방탄소년단</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>콘서트, 투모로우바이투게더, 방탄소년단</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>르세라핌, 방탄소년단</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>투모로우바이투게더, 뉴진스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>투모로우바이투게더, 방탄소년단</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>방탄소년단, 뉴진스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>뉴진스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>방탄소년단, 뉴진스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>방탄소년단, 투모로우바이투게더</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-01-16</td>\n",
       "      <td>뉴진스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>방탄소년단, 뉴진스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>방탄소년단, 뉴진스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-01-19</td>\n",
       "      <td>르세라핌, 투모로우바이투게더, 방탄소년단, 뉴진스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>방시혁, 투모로우바이투게더</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DATE_NEW                     KEYWORDS\n",
       "0  2023-01-02                  르세라핌, 방탄소년단\n",
       "1  2023-01-03        콘서트, 투모로우바이투게더, 방탄소년단\n",
       "2  2023-01-04                  르세라핌, 방탄소년단\n",
       "3  2023-01-05               투모로우바이투게더, 뉴진스\n",
       "4  2023-01-06             투모로우바이투게더, 방탄소년단\n",
       "5  2023-01-09                   방탄소년단, 뉴진스\n",
       "6  2023-01-10                          뉴진스\n",
       "7  2023-01-11                   방탄소년단, 뉴진스\n",
       "8  2023-01-12                             \n",
       "9  2023-01-13             방탄소년단, 투모로우바이투게더\n",
       "10 2023-01-16                          뉴진스\n",
       "11 2023-01-17                   방탄소년단, 뉴진스\n",
       "12 2023-01-18                   방탄소년단, 뉴진스\n",
       "13 2023-01-19  르세라핌, 투모로우바이투게더, 방탄소년단, 뉴진스\n",
       "14 2023-01-20               방시혁, 투모로우바이투게더"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_hybe_cleaned.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "094af352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_NEW</th>\n",
       "      <th>KEYWORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>소녀시대</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>콘서트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-11</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-13</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-01-16</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-01-17</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-01-18</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-01-19</td>\n",
       "      <td>슈퍼주니어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DATE_NEW KEYWORDS\n",
       "0  2023-01-02     소녀시대\n",
       "1  2023-01-03      콘서트\n",
       "2  2023-01-04         \n",
       "3  2023-01-05         \n",
       "4  2023-01-06         \n",
       "5  2023-01-09         \n",
       "6  2023-01-10         \n",
       "7  2023-01-11         \n",
       "8  2023-01-12         \n",
       "9  2023-01-13         \n",
       "10 2023-01-16         \n",
       "11 2023-01-17         \n",
       "12 2023-01-18         \n",
       "13 2023-01-19    슈퍼주니어\n",
       "14 2023-01-20         "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_sm_cleaned.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b165483e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_NEW</th>\n",
       "      <th>KEYWORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>블랙핑크, 베이비몬스터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>블랙핑크, 콘서트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>블랙핑크, 베이비몬스터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>베이비몬스터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>지드래곤, 베이비몬스터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>베이비몬스터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>지드래곤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-13</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-01-16</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-01-17</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-01-18</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-01-19</td>\n",
       "      <td>블랙핑크, 베이비몬스터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>베이비몬스터</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DATE_NEW      KEYWORDS\n",
       "0  2023-01-02  블랙핑크, 베이비몬스터\n",
       "1  2023-01-03     블랙핑크, 콘서트\n",
       "2  2023-01-04  블랙핑크, 베이비몬스터\n",
       "3  2023-01-05        베이비몬스터\n",
       "4  2023-01-06  지드래곤, 베이비몬스터\n",
       "5  2023-01-09        베이비몬스터\n",
       "6  2023-01-10              \n",
       "7  2023-01-11          지드래곤\n",
       "8  2023-01-12              \n",
       "9  2023-01-13              \n",
       "10 2023-01-16              \n",
       "11 2023-01-17              \n",
       "12 2023-01-18              \n",
       "13 2023-01-19  블랙핑크, 베이비몬스터\n",
       "14 2023-01-20        베이비몬스터"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_yg_cleaned.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "526ab7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_NEW</th>\n",
       "      <th>KEYWORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>콘서트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>트와이스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-11</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-13</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-16</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-01-17</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>스트레이키즈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-01-19</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DATE_NEW KEYWORDS\n",
       "0  2023-01-02         \n",
       "1  2023-01-03      콘서트\n",
       "2  2023-01-04     트와이스\n",
       "3  2023-01-05         \n",
       "4  2023-01-06         \n",
       "5  2023-01-10         \n",
       "6  2023-01-11         \n",
       "7  2023-01-12         \n",
       "8  2023-01-13         \n",
       "9  2023-01-16         \n",
       "10 2023-01-17         \n",
       "11 2023-01-18   스트레이키즈\n",
       "12 2023-01-19         \n",
       "13 2023-01-20         \n",
       "14 2023-01-23         "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_jyp_cleaned.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbadb0db",
   "metadata": {},
   "source": [
    "# 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0d833a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_hybe_cleaned.to_excel('../../../data/FINALDATA/keywords_hybe.xlsx', index=False)\n",
    "news_sm_cleaned.to_excel('../../../data/FINALDATA/keywords_sm.xlsx', index=False)\n",
    "news_yg_cleaned.to_excel('../../../data/FINALDATA/keywords_yg.xlsx', index=False)\n",
    "news_jyp_cleaned.to_excel('../../../data/FINALDATA/keywords_jyp.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "265.556px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
