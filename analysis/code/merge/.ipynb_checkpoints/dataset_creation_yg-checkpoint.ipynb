{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faf5854d",
   "metadata": {},
   "source": [
    "# 데이터, 패키지 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d487e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 로드 \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "799aba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 \n",
    "df_stock= pd.read_csv(\"../../data/Stock/stock+tech_yg.csv\")\n",
    "df_trend= pd.read_csv(\"../../data/Trend/trend_yg.csv\")\n",
    "df_sentiment= pd.read_excel(\"../../data/News/sentiment_yg.xlsx\")\n",
    "df_event= pd.read_excel(\"../../data/News/event_yg.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "733fa2d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123 entries, 0 to 122\n",
      "Data columns (total 18 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Date    123 non-null    object \n",
      " 1   Open    123 non-null    int64  \n",
      " 2   High    123 non-null    int64  \n",
      " 3   Low     123 non-null    int64  \n",
      " 4   Close   123 non-null    int64  \n",
      " 5   Volume  123 non-null    int64  \n",
      " 6   Change  123 non-null    float64\n",
      " 7   MACD    123 non-null    float64\n",
      " 8   Signal  123 non-null    float64\n",
      " 9   PSAR    123 non-null    float64\n",
      " 10  upper   123 non-null    float64\n",
      " 11  middle  123 non-null    float64\n",
      " 12  lower   123 non-null    float64\n",
      " 13  SlowK   123 non-null    float64\n",
      " 14  SlowD   123 non-null    float64\n",
      " 15  ROC     123 non-null    float64\n",
      " 16  OBV     123 non-null    float64\n",
      " 17  FI      123 non-null    float64\n",
      "dtypes: float64(12), int64(5), object(1)\n",
      "memory usage: 17.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_stock.info() # 주가+기술지표 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "248e5e31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 181 entries, 0 to 180\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   date               181 non-null    object \n",
      " 1   keyword            181 non-null    float64\n",
      " 2   view_log_like_sum  181 non-null    float64\n",
      " 3   view_log_like_avg  181 non-null    float64\n",
      " 4   count              181 non-null    float64\n",
      " 5   trend              181 non-null    float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 8.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_trend.info() # 트렌드(유튜브, 네이버) 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c322283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126 entries, 0 to 125\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   DATE           126 non-null    datetime64[ns]\n",
      " 1   SENTIMENT_SUM  126 non-null    float64       \n",
      " 2   DAY            126 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 3.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_sentiment.info() # 감정지수(뉴스) 변수 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f7b9201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17 entries, 0 to 16\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   DATE           17 non-null     datetime64[ns]\n",
      " 1   SENTIMENT_SUM  17 non-null     float64       \n",
      " 2   DAY            17 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 536.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_event.info() # 이벤트 변수 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab74d0d3",
   "metadata": {},
   "source": [
    "# DATE 변수타입 통일 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4192c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stock의 'Date' 열을 datetime 형식으로 변환\n",
    "df_stock['Date'] = pd.to_datetime(df_stock['Date'])\n",
    "\n",
    "# df_trend의 'date' 열을 datetime 형식으로 변환\n",
    "df_trend['date'] = pd.to_datetime(df_trend['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b851b1",
   "metadata": {},
   "source": [
    "# DATE 변수명 통일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b8abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stock의'Date' 열의 이름을 'DATE'로 변경\n",
    "df_stock = df_stock.rename(columns={'Date': 'DATE'})\n",
    "\n",
    "# df_trend의'date' 열의 이름을 'DATE'로 변경\n",
    "df_trend = df_trend.rename(columns={'date': 'DATE'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f915074",
   "metadata": {},
   "source": [
    "# df_trend 데이터의 DATE 수정 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11f3f1a",
   "metadata": {},
   "source": [
    "### 일자별 요일 지정\n",
    "향후 분석에 용이하도록 DATE_NEW 일자를 기준으로 일자별 요일을 지정해줌.\n",
    "- 2023년 1월은 일요일부터 시작함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aa1d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_dict = {0:'월', 1:'화', 2:'수', 3:'목', 4:'금', 5:'토', 6:'일'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6cf7693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAY\n",
       "금    26\n",
       "목    26\n",
       "수    26\n",
       "월    26\n",
       "일    26\n",
       "토    25\n",
       "화    26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_list = []\n",
    "\n",
    "for i in range(len(df_trend)):\n",
    "    day_list.append(weekday_dict[df_trend[\"DATE\"][i].weekday()])\n",
    "\n",
    "df_trend[\"DAY\"] = day_list\n",
    "df_trend.groupby(\"DAY\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d26645d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "월 ['2023-01-02T00:00:00.000000000' '2023-01-09T00:00:00.000000000'\n",
      " '2023-01-16T00:00:00.000000000' '2023-01-23T00:00:00.000000000'\n",
      " '2023-01-30T00:00:00.000000000' '2023-02-06T00:00:00.000000000'\n",
      " '2023-02-13T00:00:00.000000000' '2023-02-20T00:00:00.000000000'\n",
      " '2023-02-27T00:00:00.000000000' '2023-03-06T00:00:00.000000000'\n",
      " '2023-03-13T00:00:00.000000000' '2023-03-20T00:00:00.000000000'\n",
      " '2023-03-27T00:00:00.000000000' '2023-04-03T00:00:00.000000000'\n",
      " '2023-04-10T00:00:00.000000000' '2023-04-17T00:00:00.000000000'\n",
      " '2023-04-24T00:00:00.000000000' '2023-05-01T00:00:00.000000000'\n",
      " '2023-05-08T00:00:00.000000000' '2023-05-15T00:00:00.000000000'\n",
      " '2023-05-22T00:00:00.000000000' '2023-05-29T00:00:00.000000000'\n",
      " '2023-06-05T00:00:00.000000000' '2023-06-12T00:00:00.000000000'\n",
      " '2023-06-19T00:00:00.000000000' '2023-06-26T00:00:00.000000000']\n",
      "화 ['2023-01-03T00:00:00.000000000' '2023-01-10T00:00:00.000000000'\n",
      " '2023-01-17T00:00:00.000000000' '2023-01-24T00:00:00.000000000'\n",
      " '2023-01-31T00:00:00.000000000' '2023-02-07T00:00:00.000000000'\n",
      " '2023-02-14T00:00:00.000000000' '2023-02-21T00:00:00.000000000'\n",
      " '2023-02-28T00:00:00.000000000' '2023-03-07T00:00:00.000000000'\n",
      " '2023-03-14T00:00:00.000000000' '2023-03-21T00:00:00.000000000'\n",
      " '2023-03-28T00:00:00.000000000' '2023-04-04T00:00:00.000000000'\n",
      " '2023-04-11T00:00:00.000000000' '2023-04-18T00:00:00.000000000'\n",
      " '2023-04-25T00:00:00.000000000' '2023-05-02T00:00:00.000000000'\n",
      " '2023-05-09T00:00:00.000000000' '2023-05-16T00:00:00.000000000'\n",
      " '2023-05-23T00:00:00.000000000' '2023-05-30T00:00:00.000000000'\n",
      " '2023-06-06T00:00:00.000000000' '2023-06-13T00:00:00.000000000'\n",
      " '2023-06-20T00:00:00.000000000' '2023-06-27T00:00:00.000000000']\n",
      "수 ['2023-01-04T00:00:00.000000000' '2023-01-11T00:00:00.000000000'\n",
      " '2023-01-18T00:00:00.000000000' '2023-01-25T00:00:00.000000000'\n",
      " '2023-02-01T00:00:00.000000000' '2023-02-08T00:00:00.000000000'\n",
      " '2023-02-15T00:00:00.000000000' '2023-02-22T00:00:00.000000000'\n",
      " '2023-03-01T00:00:00.000000000' '2023-03-08T00:00:00.000000000'\n",
      " '2023-03-15T00:00:00.000000000' '2023-03-22T00:00:00.000000000'\n",
      " '2023-03-29T00:00:00.000000000' '2023-04-05T00:00:00.000000000'\n",
      " '2023-04-12T00:00:00.000000000' '2023-04-19T00:00:00.000000000'\n",
      " '2023-04-26T00:00:00.000000000' '2023-05-03T00:00:00.000000000'\n",
      " '2023-05-10T00:00:00.000000000' '2023-05-17T00:00:00.000000000'\n",
      " '2023-05-24T00:00:00.000000000' '2023-05-31T00:00:00.000000000'\n",
      " '2023-06-07T00:00:00.000000000' '2023-06-14T00:00:00.000000000'\n",
      " '2023-06-21T00:00:00.000000000' '2023-06-28T00:00:00.000000000']\n",
      "목 ['2023-01-05T00:00:00.000000000' '2023-01-12T00:00:00.000000000'\n",
      " '2023-01-19T00:00:00.000000000' '2023-01-26T00:00:00.000000000'\n",
      " '2023-02-02T00:00:00.000000000' '2023-02-09T00:00:00.000000000'\n",
      " '2023-02-16T00:00:00.000000000' '2023-02-23T00:00:00.000000000'\n",
      " '2023-03-02T00:00:00.000000000' '2023-03-09T00:00:00.000000000'\n",
      " '2023-03-16T00:00:00.000000000' '2023-03-23T00:00:00.000000000'\n",
      " '2023-03-30T00:00:00.000000000' '2023-04-06T00:00:00.000000000'\n",
      " '2023-04-13T00:00:00.000000000' '2023-04-20T00:00:00.000000000'\n",
      " '2023-04-27T00:00:00.000000000' '2023-05-04T00:00:00.000000000'\n",
      " '2023-05-11T00:00:00.000000000' '2023-05-18T00:00:00.000000000'\n",
      " '2023-05-25T00:00:00.000000000' '2023-06-01T00:00:00.000000000'\n",
      " '2023-06-08T00:00:00.000000000' '2023-06-15T00:00:00.000000000'\n",
      " '2023-06-22T00:00:00.000000000' '2023-06-29T00:00:00.000000000']\n",
      "금 ['2023-01-06T00:00:00.000000000' '2023-01-13T00:00:00.000000000'\n",
      " '2023-01-20T00:00:00.000000000' '2023-01-27T00:00:00.000000000'\n",
      " '2023-02-03T00:00:00.000000000' '2023-02-10T00:00:00.000000000'\n",
      " '2023-02-17T00:00:00.000000000' '2023-02-24T00:00:00.000000000'\n",
      " '2023-03-03T00:00:00.000000000' '2023-03-10T00:00:00.000000000'\n",
      " '2023-03-17T00:00:00.000000000' '2023-03-24T00:00:00.000000000'\n",
      " '2023-03-31T00:00:00.000000000' '2023-04-07T00:00:00.000000000'\n",
      " '2023-04-14T00:00:00.000000000' '2023-04-21T00:00:00.000000000'\n",
      " '2023-04-28T00:00:00.000000000' '2023-05-05T00:00:00.000000000'\n",
      " '2023-05-12T00:00:00.000000000' '2023-05-19T00:00:00.000000000'\n",
      " '2023-05-26T00:00:00.000000000' '2023-06-02T00:00:00.000000000'\n",
      " '2023-06-09T00:00:00.000000000' '2023-06-16T00:00:00.000000000'\n",
      " '2023-06-23T00:00:00.000000000' '2023-06-30T00:00:00.000000000']\n",
      "토 ['2023-01-07T00:00:00.000000000' '2023-01-14T00:00:00.000000000'\n",
      " '2023-01-21T00:00:00.000000000' '2023-01-28T00:00:00.000000000'\n",
      " '2023-02-04T00:00:00.000000000' '2023-02-11T00:00:00.000000000'\n",
      " '2023-02-18T00:00:00.000000000' '2023-02-25T00:00:00.000000000'\n",
      " '2023-03-04T00:00:00.000000000' '2023-03-11T00:00:00.000000000'\n",
      " '2023-03-18T00:00:00.000000000' '2023-03-25T00:00:00.000000000'\n",
      " '2023-04-01T00:00:00.000000000' '2023-04-08T00:00:00.000000000'\n",
      " '2023-04-15T00:00:00.000000000' '2023-04-22T00:00:00.000000000'\n",
      " '2023-04-29T00:00:00.000000000' '2023-05-06T00:00:00.000000000'\n",
      " '2023-05-13T00:00:00.000000000' '2023-05-20T00:00:00.000000000'\n",
      " '2023-05-27T00:00:00.000000000' '2023-06-03T00:00:00.000000000'\n",
      " '2023-06-10T00:00:00.000000000' '2023-06-17T00:00:00.000000000'\n",
      " '2023-06-24T00:00:00.000000000']\n",
      "일 ['2023-01-01T00:00:00.000000000' '2023-01-08T00:00:00.000000000'\n",
      " '2023-01-15T00:00:00.000000000' '2023-01-22T00:00:00.000000000'\n",
      " '2023-01-29T00:00:00.000000000' '2023-02-05T00:00:00.000000000'\n",
      " '2023-02-12T00:00:00.000000000' '2023-02-19T00:00:00.000000000'\n",
      " '2023-02-26T00:00:00.000000000' '2023-03-05T00:00:00.000000000'\n",
      " '2023-03-12T00:00:00.000000000' '2023-03-19T00:00:00.000000000'\n",
      " '2023-03-26T00:00:00.000000000' '2023-04-02T00:00:00.000000000'\n",
      " '2023-04-09T00:00:00.000000000' '2023-04-16T00:00:00.000000000'\n",
      " '2023-04-23T00:00:00.000000000' '2023-04-30T00:00:00.000000000'\n",
      " '2023-05-07T00:00:00.000000000' '2023-05-14T00:00:00.000000000'\n",
      " '2023-05-21T00:00:00.000000000' '2023-05-28T00:00:00.000000000'\n",
      " '2023-06-04T00:00:00.000000000' '2023-06-11T00:00:00.000000000'\n",
      " '2023-06-18T00:00:00.000000000' '2023-06-25T00:00:00.000000000']\n"
     ]
    }
   ],
   "source": [
    "#요일 배정이 잘 되었는지 확인\n",
    "for day in weekday_dict.values():\n",
    "    print(day, df_trend[df_trend[\"DAY\"] == day][\"DATE\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a788ac6",
   "metadata": {},
   "source": [
    "- **설명**\n",
    "- '요일' 변수는 각 뉴스가 영향을 미치는 요일을 의미한다 \n",
    "- ex1) 요일이 '금'으로 지정된 데이터 : 금요일 주가에 영향을 미치는 데이터 \n",
    "- ex2) 요일이 '토'으로 지정된 데이터 : 금요일 주가에 영향을 미치는 데이터 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee1522",
   "metadata": {},
   "source": [
    "* **토요일, 일요일 데이터 전처리**\n",
    "- 토요일과 일요일 데이터는 ***월요일*** 주가에 영향을 미친다\n",
    "- 따라서 요일 변수가 토요일, 일요일로 설정된 데이터들은 그 다음주 월요일 데이터로 간주하여 날짜 및 요일 변수를 변경한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36b20a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23828/3245083037.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend['DATE'].iloc[i]+= datetime.timedelta(days=1)  # DATE_NEW(날짜)변수에 하루를 추가\n",
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23828/3245083037.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend['DAY'].iloc[i] = '월'       #DAY(요일) 변수를 월요일로\n",
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23828/3245083037.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend['DATE'].iloc[i]+= datetime.timedelta(days=2)  # DATE_NEW(날짜)변수에 이틀을 추가\n",
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23828/3245083037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend['DAY'].iloc[i] = '월'       #DAY(요일) 변수를 월요일로\n"
     ]
    }
   ],
   "source": [
    " for i in range(len(df_trend)):\n",
    "    if (df_trend['DAY'].iloc[i] == '토'): # 토요일 뉴스기사라면, \n",
    "        df_trend['DATE'].iloc[i]+= datetime.timedelta(days=2)  # DATE_NEW(날짜)변수에 이틀을 추가\n",
    "        df_trend['DAY'].iloc[i] = '월'       #DAY(요일) 변수를 월요일로\n",
    "    if (df_trend['DAY'].iloc[i] == '일'): # 일요일 뉴스기사라면, \n",
    "        df_trend['DATE'].iloc[i]+= datetime.timedelta(days=1)  # DATE_NEW(날짜)변수에 하루를 추가\n",
    "        df_trend['DAY'].iloc[i] = '월'       #DAY(요일) 변수를 월요일로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d37bb44",
   "metadata": {},
   "source": [
    "### 월요일 데이터들의 변수 값 평균 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221a8008",
   "metadata": {},
   "source": [
    "- df_trend에서 DAY 변수의 값이 '월'인 행들은 DATE 변수로 GROUPBY 한 뒤 keyword, view_log_like_sum, view_log_like_avg, count, trend 변수의 평균값을 구할 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05fe83ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>keyword</th>\n",
       "      <th>view_log_like_sum</th>\n",
       "      <th>view_log_like_avg</th>\n",
       "      <th>count</th>\n",
       "      <th>trend</th>\n",
       "      <th>DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>69.27633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.168034</td>\n",
       "      <td>월</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>54.72752</td>\n",
       "      <td>128543.987852</td>\n",
       "      <td>32135.996963</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>7.950054</td>\n",
       "      <td>월</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-16</td>\n",
       "      <td>40.25447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.723044</td>\n",
       "      <td>월</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>36.11070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.611786</td>\n",
       "      <td>월</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>43.85233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.952521</td>\n",
       "      <td>월</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE   keyword  view_log_like_sum  view_log_like_avg     count  \\\n",
       "0 2023-01-02  69.27633           0.000000           0.000000  0.000000   \n",
       "1 2023-01-09  54.72752      128543.987852       32135.996963  1.333333   \n",
       "2 2023-01-16  40.25447           0.000000           0.000000  0.000000   \n",
       "3 2023-01-23  36.11070           0.000000           0.000000  0.000000   \n",
       "4 2023-01-30  43.85233           0.000000           0.000000  0.000000   \n",
       "\n",
       "      trend DAY  \n",
       "0  4.168034   월  \n",
       "1  7.950054   월  \n",
       "2  3.723044   월  \n",
       "3  3.611786   월  \n",
       "4  3.952521   월  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'DAY' 변수가 '월'인 행 필터링\n",
    "df_trend_monday = df_trend[df_trend['DAY'] == '월']\n",
    "df_trend_notmonday = df_trend[df_trend['DAY'] != '월']\n",
    "\n",
    "# 'DATE' 변수로 그룹화하여 변수들의 평균값 구하기\n",
    "df_trend_monday = df_trend_monday.groupby('DATE').agg({\n",
    "    'keyword': 'first',  # 첫 번째 키워드 선택\n",
    "    'view_log_like_sum': 'mean',\n",
    "    'view_log_like_avg': 'mean',\n",
    "    'count': 'mean',\n",
    "    'trend': 'mean',\n",
    "    'DAY': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# 결과 출력\n",
    "df_trend_monday.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66815cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 월요일 데이터, 월요일이 아닌 데이터 다시 합치기 \n",
    "df_trend = pd.concat([df_trend_monday, df_trend_notmonday], axis=0)\n",
    "\n",
    "# 행 인덱스 초기화\n",
    "df_trend = df_trend.reset_index(drop=True)\n",
    "\n",
    "# 'DATE' 변수로 정렬\n",
    "df_trend = df_trend.sort_values(by='DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "874a6b12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE                 130\n",
       "keyword              129\n",
       "view_log_like_sum     39\n",
       "view_log_like_avg     39\n",
       "count                  5\n",
       "trend                130\n",
       "DAY                    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trend.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755e161b",
   "metadata": {},
   "source": [
    "# df_trend, df_sentiment, df_event 의 날짜 변수를 df_stock 에 맞추기 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c129280",
   "metadata": {},
   "source": [
    "##  df_stock와 df_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "581d7ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_trend와 df_stock의 'DATE' 열에서 다른 원소:\n",
      "{Timestamp('2023-01-24 00:00:00'), Timestamp('2023-05-05 00:00:00'), Timestamp('2023-01-23 00:00:00'), Timestamp('2023-06-06 00:00:00'), Timestamp('2023-05-29 00:00:00'), Timestamp('2023-03-01 00:00:00'), Timestamp('2023-05-01 00:00:00')}\n"
     ]
    }
   ],
   "source": [
    "set_trend_dates = set(df_trend['DATE'])\n",
    "set_stock_dates = set(df_stock['DATE'])\n",
    "\n",
    "# 차이를 확인하여 다른 원소를 추출\n",
    "difference = set_trend_dates.symmetric_difference(set_stock_dates)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"df_trend와 df_stock의 'DATE' 열에서 다른 원소:\")\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5032aab1",
   "metadata": {},
   "source": [
    "- 1/23 : 설 연휴\n",
    "- 1/24 : 설 연휴 \n",
    "- 3/1 : 삼일절\n",
    "- 5/1 : 노동절\n",
    "- 5/5 : 어린이날\n",
    "- 5/29 : 석가탄신일\n",
    "- 6/6 : 현충일 \n",
    "- 해당 일자들은 주식 시장이 개장하지 않는 일자임\n",
    "- 따라서 df_trend 에서 1/23, 1/24, 1/25에 대한 변수들의 값을 더한 뒤 평균을 내주는 식의 방법을 사용함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fc2d977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1월 23일, 1월 24일, 1월 25일 데이터 필터링\n",
    "selected_dates = ['2023-01-23', '2023-01-24', '2023-01-25']\n",
    "filtered_df = df_trend[df_trend['DATE'].isin(selected_dates)]\n",
    "\n",
    "# 1월 23일, 1월 24일 데이터 삭제\n",
    "df_trend = df_trend[df_trend['DATE'] != '2023-01-23']\n",
    "df_trend = df_trend[df_trend['DATE'] != '2023-01-24']\n",
    "\n",
    "# 1월 25일 데이터를 평균값으로 대체\n",
    "average_values = filtered_df.mean(numeric_only=True)\n",
    "df_trend.loc[df_trend['DATE'] == '2023-01-25', ['keyword', 'view_log_like_sum', 'view_log_like_avg', 'count', 'trend']] = average_values.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb2e023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업할 날짜 쌍 정의\n",
    "date_pairs = [('2023-03-01', '2023-03-02'), ('2023-05-01', '2023-05-02'), ('2023-05-05', '2023-05-08'), ('2023-05-29', '2023-05-30'), ('2023-06-06', '2023-06-07')]\n",
    "\n",
    "# 날짜 쌍에 대한 반복 작업\n",
    "for start_date, end_date in date_pairs:\n",
    "    # 선택한 날짜 데이터 필터링\n",
    "    selected_dates = [start_date, end_date]\n",
    "    filtered_df = df_trend[df_trend['DATE'].isin(selected_dates)]\n",
    "\n",
    "    # 시작 날짜 데이터 삭제\n",
    "    df_trend = df_trend[df_trend['DATE'] != start_date]\n",
    "\n",
    "    # 끝 날짜 데이터를 평균값으로 대체\n",
    "    average_values = filtered_df.mean(numeric_only=True)\n",
    "    df_trend.loc[df_trend['DATE'] == end_date, ['keyword', 'view_log_like_sum', 'view_log_like_avg', 'count', 'trend']] = average_values[['keyword', 'view_log_like_sum', 'view_log_like_avg', 'count', 'trend']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b56db8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_trend와 df_stock의 'DATE' 열에서 다른 원소:\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# 차이 없는지 확인\n",
    "\n",
    "set_trend_dates = set(df_trend['DATE'])\n",
    "set_stock_dates = set(df_stock['DATE'])\n",
    "\n",
    "# 차이를 확인하여 다른 원소를 추출\n",
    "difference = set_trend_dates.symmetric_difference(set_stock_dates)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"df_trend와 df_stock의 'DATE' 열에서 다른 원소:\")\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaa262f",
   "metadata": {},
   "source": [
    "##  df_stock와 df_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2049be88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_sentiment_dates df_stock의 'DATE' 열에서 다른 원소:\n",
      "{Timestamp('2023-01-24 00:00:00'), Timestamp('2023-06-29 00:00:00'), Timestamp('2023-06-27 00:00:00'), Timestamp('2023-05-05 00:00:00'), Timestamp('2023-01-23 00:00:00'), Timestamp('2023-06-06 00:00:00'), Timestamp('2023-06-30 00:00:00'), Timestamp('2023-05-29 00:00:00'), Timestamp('2023-03-01 00:00:00'), Timestamp('2023-05-01 00:00:00'), Timestamp('2023-06-28 00:00:00')}\n"
     ]
    }
   ],
   "source": [
    "set_sentiment_dates = set(df_sentiment['DATE'])\n",
    "set_stock_dates = set(df_stock['DATE'])\n",
    "\n",
    "# 차이를 확인하여 다른 원소를 추출\n",
    "difference = set_sentiment_dates.symmetric_difference(set_stock_dates)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"set_sentiment_dates df_stock의 'DATE' 열에서 다른 원소:\")\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d219d97",
   "metadata": {},
   "source": [
    "- 1/23 : 설 연휴\n",
    "- 1/24 : 설 연휴 \n",
    "- 3/1 : 삼일절\n",
    "- 5/5 : 어린이날\n",
    "- 5/29 : 석가탄신일\n",
    "- 6/6 : 현충일 \n",
    "- 해당 일자들은 주식 시장이 개장하지 않는 일자임\n",
    "- 따라서 df_trend 에서 1/23, 1/24, 1/25에 대한 변수들의 값을 더한 뒤 평균을 내주는 식의 방법을 사용함 \n",
    "\n",
    "- 3/31 : \n",
    "- 6/27 : \n",
    "- 6/28 : \n",
    "- 6/29 : \n",
    "- 6/30 : \n",
    "- 해당 일자들은 df_sentiment 값이 존재하지 않는(영상 등이 올라오지 않은) 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de6b5e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1월 23일, 1월 24일, 1월 25일 데이터 필터링\n",
    "selected_dates = ['2023-01-23', '2023-01-24', '2023-01-25']\n",
    "filtered_df = df_sentiment[df_sentiment['DATE'].isin(selected_dates)]\n",
    "\n",
    "# 1월 23일, 1월 24일 데이터 삭제\n",
    "df_sentiment = df_sentiment[df_sentiment['DATE'] != '2023-01-23']\n",
    "df_sentiment = df_sentiment[df_sentiment['DATE'] != '2023-01-24']\n",
    "\n",
    "# 1월 25일 데이터를 평균값으로 대체\n",
    "average_values = filtered_df.mean(numeric_only=True)\n",
    "df_sentiment.loc[df_sentiment['DATE'] == '2023-01-25', 'SENTIMENT_SUM'] = average_values.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9f75684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업할 날짜 쌍 정의\n",
    "date_pairs = [('2023-03-01', '2023-03-02'), ('2023-05-05', '2023-05-08'),('2023-05-29', '2023-05-30'), ('2023-06-06', '2023-06-07')]\n",
    "\n",
    "# 날짜 쌍에 대한 반복 작업\n",
    "for start_date, end_date in date_pairs:\n",
    "    # 선택한 날짜 데이터 필터링\n",
    "    selected_dates = [start_date, end_date]\n",
    "    filtered_df = df_sentiment[df_sentiment['DATE'].isin(selected_dates)]\n",
    "\n",
    "    # 시작 날짜 데이터 삭제\n",
    "    df_sentiment = df_sentiment[df_sentiment['DATE'] != start_date]\n",
    "\n",
    "    # 끝 날짜 데이터를 평균값으로 대체\n",
    "    average_values = filtered_df.mean(numeric_only=True)\n",
    "    df_sentiment.loc[df_sentiment['DATE'] == end_date, 'SENTIMENT_SUM'] = average_values.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bab24e9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_sentiment와 df_stock의 'DATE' 열에서 다른 원소:\n",
      "{Timestamp('2023-06-29 00:00:00'), Timestamp('2023-06-27 00:00:00'), Timestamp('2023-06-30 00:00:00'), Timestamp('2023-05-01 00:00:00'), Timestamp('2023-06-28 00:00:00')}\n"
     ]
    }
   ],
   "source": [
    "# 결측치를 제외하고 차이 없는지 확인\n",
    "\n",
    "set_sentiment_dates = set(df_sentiment['DATE'])\n",
    "set_stock_dates = set(df_stock['DATE'])\n",
    "\n",
    "# 차이를 확인하여 다른 원소를 추출\n",
    "difference = set_sentiment_dates.symmetric_difference(set_stock_dates)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"df_sentiment와 df_stock의 'DATE' 열에서 다른 원소:\")\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b163b8d8",
   "metadata": {},
   "source": [
    "# DATE 기준으로 데이터프레임 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ba61eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "123\n",
      "120\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "print(df_stock['DATE'].nunique())\n",
    "print(df_trend['DATE'].nunique())\n",
    "print(df_sentiment['DATE'].nunique())\n",
    "print(df_event['DATE'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1303efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 병합\n",
    "merged_df = df_stock.merge(df_trend, on='DATE', how='outer')\n",
    "merged_df = merged_df.merge(df_sentiment, on='DATE', how='outer')\n",
    "merged_df = merged_df.merge(df_event, on='DATE', how='outer')\n",
    "\n",
    "# 날짜로 정렬\n",
    "merged_df['DATE'] = pd.to_datetime(merged_df['DATE'])\n",
    "merged_df = merged_df.sort_values(by='DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38445945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Change</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal</th>\n",
       "      <th>PSAR</th>\n",
       "      <th>...</th>\n",
       "      <th>keyword</th>\n",
       "      <th>view_log_like_sum</th>\n",
       "      <th>view_log_like_avg</th>\n",
       "      <th>count</th>\n",
       "      <th>trend</th>\n",
       "      <th>DAY_x</th>\n",
       "      <th>SENTIMENT_SUM_x</th>\n",
       "      <th>DAY_y</th>\n",
       "      <th>SENTIMENT_SUM_y</th>\n",
       "      <th>DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>46550.0</td>\n",
       "      <td>49000.0</td>\n",
       "      <td>45950.0</td>\n",
       "      <td>48050.0</td>\n",
       "      <td>1483247.0</td>\n",
       "      <td>0.095781</td>\n",
       "      <td>686.685188</td>\n",
       "      <td>731.113168</td>\n",
       "      <td>42450.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>69.27633</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.168034</td>\n",
       "      <td>월</td>\n",
       "      <td>126.027702</td>\n",
       "      <td>월</td>\n",
       "      <td>28.548385</td>\n",
       "      <td>월</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>47500.0</td>\n",
       "      <td>50800.0</td>\n",
       "      <td>47500.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>1176815.0</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>977.776846</td>\n",
       "      <td>780.445904</td>\n",
       "      <td>42450.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60.65854</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.105260</td>\n",
       "      <td>화</td>\n",
       "      <td>119.020563</td>\n",
       "      <td>화</td>\n",
       "      <td>-33.331533</td>\n",
       "      <td>화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>49800.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>48350.0</td>\n",
       "      <td>48800.0</td>\n",
       "      <td>505379.0</td>\n",
       "      <td>-0.014141</td>\n",
       "      <td>1138.856898</td>\n",
       "      <td>852.128103</td>\n",
       "      <td>42784.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53.81251</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.985506</td>\n",
       "      <td>수</td>\n",
       "      <td>209.513567</td>\n",
       "      <td>수</td>\n",
       "      <td>74.965736</td>\n",
       "      <td>수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>49250.0</td>\n",
       "      <td>50100.0</td>\n",
       "      <td>48250.0</td>\n",
       "      <td>49100.0</td>\n",
       "      <td>445150.0</td>\n",
       "      <td>0.006148</td>\n",
       "      <td>1276.012416</td>\n",
       "      <td>936.904965</td>\n",
       "      <td>43104.640000</td>\n",
       "      <td>...</td>\n",
       "      <td>51.66778</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.944834</td>\n",
       "      <td>목</td>\n",
       "      <td>277.915244</td>\n",
       "      <td>목</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>48700.0</td>\n",
       "      <td>49900.0</td>\n",
       "      <td>46950.0</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>580137.0</td>\n",
       "      <td>0.010183</td>\n",
       "      <td>1408.815031</td>\n",
       "      <td>1031.286979</td>\n",
       "      <td>43412.454400</td>\n",
       "      <td>...</td>\n",
       "      <td>45.43369</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.816254</td>\n",
       "      <td>금</td>\n",
       "      <td>269.611104</td>\n",
       "      <td>금</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2023-06-26</td>\n",
       "      <td>77600.0</td>\n",
       "      <td>78700.0</td>\n",
       "      <td>76600.0</td>\n",
       "      <td>77200.0</td>\n",
       "      <td>219672.0</td>\n",
       "      <td>-0.010256</td>\n",
       "      <td>-274.988847</td>\n",
       "      <td>1400.729619</td>\n",
       "      <td>83589.187649</td>\n",
       "      <td>...</td>\n",
       "      <td>36.15345</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.558157</td>\n",
       "      <td>월</td>\n",
       "      <td>282.396226</td>\n",
       "      <td>월</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2023-06-27</td>\n",
       "      <td>76800.0</td>\n",
       "      <td>80400.0</td>\n",
       "      <td>76500.0</td>\n",
       "      <td>78900.0</td>\n",
       "      <td>438592.0</td>\n",
       "      <td>0.022021</td>\n",
       "      <td>-454.030222</td>\n",
       "      <td>1029.777651</td>\n",
       "      <td>82191.350119</td>\n",
       "      <td>...</td>\n",
       "      <td>36.76734</td>\n",
       "      <td>2.716231e+06</td>\n",
       "      <td>679057.811532</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.677466</td>\n",
       "      <td>화</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2023-06-28</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>80200.0</td>\n",
       "      <td>78100.0</td>\n",
       "      <td>78500.0</td>\n",
       "      <td>246068.0</td>\n",
       "      <td>-0.005070</td>\n",
       "      <td>-621.039502</td>\n",
       "      <td>699.614220</td>\n",
       "      <td>81053.080095</td>\n",
       "      <td>...</td>\n",
       "      <td>37.15977</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.615227</td>\n",
       "      <td>수</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2023-06-29</td>\n",
       "      <td>78900.0</td>\n",
       "      <td>81800.0</td>\n",
       "      <td>76800.0</td>\n",
       "      <td>78400.0</td>\n",
       "      <td>370929.0</td>\n",
       "      <td>-0.001274</td>\n",
       "      <td>-752.787063</td>\n",
       "      <td>409.133964</td>\n",
       "      <td>76500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>38.06506</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.639297</td>\n",
       "      <td>목</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>78800.0</td>\n",
       "      <td>79800.0</td>\n",
       "      <td>76800.0</td>\n",
       "      <td>76900.0</td>\n",
       "      <td>302507.0</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-967.087436</td>\n",
       "      <td>133.889684</td>\n",
       "      <td>76606.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.39338</td>\n",
       "      <td>2.938695e+05</td>\n",
       "      <td>73467.376172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.386855</td>\n",
       "      <td>금</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE     Open     High      Low    Close     Volume    Change  \\\n",
       "0   2023-01-02  46550.0  49000.0  45950.0  48050.0  1483247.0  0.095781   \n",
       "1   2023-01-03  47500.0  50800.0  47500.0  49500.0  1176815.0  0.030177   \n",
       "2   2023-01-04  49800.0  50000.0  48350.0  48800.0   505379.0 -0.014141   \n",
       "3   2023-01-05  49250.0  50100.0  48250.0  49100.0   445150.0  0.006148   \n",
       "4   2023-01-06  48700.0  49900.0  46950.0  49600.0   580137.0  0.010183   \n",
       "..         ...      ...      ...      ...      ...        ...       ...   \n",
       "118 2023-06-26  77600.0  78700.0  76600.0  77200.0   219672.0 -0.010256   \n",
       "119 2023-06-27  76800.0  80400.0  76500.0  78900.0   438592.0  0.022021   \n",
       "120 2023-06-28  80000.0  80200.0  78100.0  78500.0   246068.0 -0.005070   \n",
       "121 2023-06-29  78900.0  81800.0  76800.0  78400.0   370929.0 -0.001274   \n",
       "122 2023-06-30  78800.0  79800.0  76800.0  76900.0   302507.0 -0.019133   \n",
       "\n",
       "            MACD       Signal          PSAR  ...   keyword  view_log_like_sum  \\\n",
       "0     686.685188   731.113168  42450.000000  ...  69.27633       0.000000e+00   \n",
       "1     977.776846   780.445904  42450.000000  ...  60.65854       0.000000e+00   \n",
       "2    1138.856898   852.128103  42784.000000  ...  53.81251       0.000000e+00   \n",
       "3    1276.012416   936.904965  43104.640000  ...  51.66778       0.000000e+00   \n",
       "4    1408.815031  1031.286979  43412.454400  ...  45.43369       0.000000e+00   \n",
       "..           ...          ...           ...  ...       ...                ...   \n",
       "118  -274.988847  1400.729619  83589.187649  ...  36.15345       0.000000e+00   \n",
       "119  -454.030222  1029.777651  82191.350119  ...  36.76734       2.716231e+06   \n",
       "120  -621.039502   699.614220  81053.080095  ...  37.15977       0.000000e+00   \n",
       "121  -752.787063   409.133964  76500.000000  ...  38.06506       0.000000e+00   \n",
       "122  -967.087436   133.889684  76606.000000  ...  34.39338       2.938695e+05   \n",
       "\n",
       "     view_log_like_avg  count      trend  DAY_x  SENTIMENT_SUM_x  DAY_y  \\\n",
       "0             0.000000    0.0   4.168034      월       126.027702      월   \n",
       "1             0.000000    0.0   4.105260      화       119.020563      화   \n",
       "2             0.000000    0.0   3.985506      수       209.513567      수   \n",
       "3             0.000000    0.0   3.944834      목       277.915244      목   \n",
       "4             0.000000    0.0   3.816254      금       269.611104      금   \n",
       "..                 ...    ...        ...    ...              ...    ...   \n",
       "118           0.000000    0.0   3.558157      월       282.396226      월   \n",
       "119      679057.811532    4.0  17.677466      화              NaN    NaN   \n",
       "120           0.000000    0.0   3.615227      수              NaN    NaN   \n",
       "121           0.000000    0.0   3.639297      목              NaN    NaN   \n",
       "122       73467.376172    4.0  15.386855      금              NaN    NaN   \n",
       "\n",
       "     SENTIMENT_SUM_y  DAY  \n",
       "0          28.548385    월  \n",
       "1         -33.331533    화  \n",
       "2          74.965736    수  \n",
       "3                NaN  NaN  \n",
       "4                NaN  NaN  \n",
       "..               ...  ...  \n",
       "118              NaN  NaN  \n",
       "119              NaN  NaN  \n",
       "120              NaN  NaN  \n",
       "121              NaN  NaN  \n",
       "122              NaN  NaN  \n",
       "\n",
       "[124 rows x 28 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d95d9ffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Change</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal</th>\n",
       "      <th>PSAR</th>\n",
       "      <th>...</th>\n",
       "      <th>OBV</th>\n",
       "      <th>FI</th>\n",
       "      <th>keyword</th>\n",
       "      <th>view_log_like_sum</th>\n",
       "      <th>view_log_like_avg</th>\n",
       "      <th>count</th>\n",
       "      <th>trend</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>46550.0</td>\n",
       "      <td>49000.0</td>\n",
       "      <td>45950.0</td>\n",
       "      <td>48050.0</td>\n",
       "      <td>1483247.0</td>\n",
       "      <td>0.095781</td>\n",
       "      <td>686.685188</td>\n",
       "      <td>731.113168</td>\n",
       "      <td>42450.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2124425.0</td>\n",
       "      <td>6.229637e+09</td>\n",
       "      <td>69.27633</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.168034</td>\n",
       "      <td>월</td>\n",
       "      <td>126.027702</td>\n",
       "      <td>28.548385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>47500.0</td>\n",
       "      <td>50800.0</td>\n",
       "      <td>47500.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>1176815.0</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>977.776846</td>\n",
       "      <td>780.445904</td>\n",
       "      <td>42450.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3301240.0</td>\n",
       "      <td>1.706382e+09</td>\n",
       "      <td>60.65854</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.105260</td>\n",
       "      <td>화</td>\n",
       "      <td>119.020563</td>\n",
       "      <td>-33.331533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>49800.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>48350.0</td>\n",
       "      <td>48800.0</td>\n",
       "      <td>505379.0</td>\n",
       "      <td>-0.014141</td>\n",
       "      <td>1138.856898</td>\n",
       "      <td>852.128103</td>\n",
       "      <td>42784.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2795861.0</td>\n",
       "      <td>-3.537653e+08</td>\n",
       "      <td>53.81251</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.985506</td>\n",
       "      <td>수</td>\n",
       "      <td>209.513567</td>\n",
       "      <td>74.965736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>49250.0</td>\n",
       "      <td>50100.0</td>\n",
       "      <td>48250.0</td>\n",
       "      <td>49100.0</td>\n",
       "      <td>445150.0</td>\n",
       "      <td>0.006148</td>\n",
       "      <td>1276.012416</td>\n",
       "      <td>936.904965</td>\n",
       "      <td>43104.640000</td>\n",
       "      <td>...</td>\n",
       "      <td>3241011.0</td>\n",
       "      <td>1.335450e+08</td>\n",
       "      <td>51.66778</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.944834</td>\n",
       "      <td>목</td>\n",
       "      <td>277.915244</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>48700.0</td>\n",
       "      <td>49900.0</td>\n",
       "      <td>46950.0</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>580137.0</td>\n",
       "      <td>0.010183</td>\n",
       "      <td>1408.815031</td>\n",
       "      <td>1031.286979</td>\n",
       "      <td>43412.454400</td>\n",
       "      <td>...</td>\n",
       "      <td>3821148.0</td>\n",
       "      <td>2.900685e+08</td>\n",
       "      <td>45.43369</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.816254</td>\n",
       "      <td>금</td>\n",
       "      <td>269.611104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2023-06-26</td>\n",
       "      <td>77600.0</td>\n",
       "      <td>78700.0</td>\n",
       "      <td>76600.0</td>\n",
       "      <td>77200.0</td>\n",
       "      <td>219672.0</td>\n",
       "      <td>-0.010256</td>\n",
       "      <td>-274.988847</td>\n",
       "      <td>1400.729619</td>\n",
       "      <td>83589.187649</td>\n",
       "      <td>...</td>\n",
       "      <td>10771841.0</td>\n",
       "      <td>-1.757376e+08</td>\n",
       "      <td>36.15345</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.558157</td>\n",
       "      <td>월</td>\n",
       "      <td>282.396226</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2023-06-27</td>\n",
       "      <td>76800.0</td>\n",
       "      <td>80400.0</td>\n",
       "      <td>76500.0</td>\n",
       "      <td>78900.0</td>\n",
       "      <td>438592.0</td>\n",
       "      <td>0.022021</td>\n",
       "      <td>-454.030222</td>\n",
       "      <td>1029.777651</td>\n",
       "      <td>82191.350119</td>\n",
       "      <td>...</td>\n",
       "      <td>11210433.0</td>\n",
       "      <td>7.456064e+08</td>\n",
       "      <td>36.76734</td>\n",
       "      <td>2.716231e+06</td>\n",
       "      <td>679057.811532</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.677466</td>\n",
       "      <td>화</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2023-06-28</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>80200.0</td>\n",
       "      <td>78100.0</td>\n",
       "      <td>78500.0</td>\n",
       "      <td>246068.0</td>\n",
       "      <td>-0.005070</td>\n",
       "      <td>-621.039502</td>\n",
       "      <td>699.614220</td>\n",
       "      <td>81053.080095</td>\n",
       "      <td>...</td>\n",
       "      <td>10964365.0</td>\n",
       "      <td>-9.842720e+07</td>\n",
       "      <td>37.15977</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.615227</td>\n",
       "      <td>수</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2023-06-29</td>\n",
       "      <td>78900.0</td>\n",
       "      <td>81800.0</td>\n",
       "      <td>76800.0</td>\n",
       "      <td>78400.0</td>\n",
       "      <td>370929.0</td>\n",
       "      <td>-0.001274</td>\n",
       "      <td>-752.787063</td>\n",
       "      <td>409.133964</td>\n",
       "      <td>76500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10593436.0</td>\n",
       "      <td>-3.709290e+07</td>\n",
       "      <td>38.06506</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.639297</td>\n",
       "      <td>목</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>78800.0</td>\n",
       "      <td>79800.0</td>\n",
       "      <td>76800.0</td>\n",
       "      <td>76900.0</td>\n",
       "      <td>302507.0</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>-967.087436</td>\n",
       "      <td>133.889684</td>\n",
       "      <td>76606.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10290929.0</td>\n",
       "      <td>-4.537605e+08</td>\n",
       "      <td>34.39338</td>\n",
       "      <td>2.938695e+05</td>\n",
       "      <td>73467.376172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.386855</td>\n",
       "      <td>금</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE     Open     High      Low    Close     Volume    Change  \\\n",
       "0   2023-01-02  46550.0  49000.0  45950.0  48050.0  1483247.0  0.095781   \n",
       "1   2023-01-03  47500.0  50800.0  47500.0  49500.0  1176815.0  0.030177   \n",
       "2   2023-01-04  49800.0  50000.0  48350.0  48800.0   505379.0 -0.014141   \n",
       "3   2023-01-05  49250.0  50100.0  48250.0  49100.0   445150.0  0.006148   \n",
       "4   2023-01-06  48700.0  49900.0  46950.0  49600.0   580137.0  0.010183   \n",
       "..         ...      ...      ...      ...      ...        ...       ...   \n",
       "118 2023-06-26  77600.0  78700.0  76600.0  77200.0   219672.0 -0.010256   \n",
       "119 2023-06-27  76800.0  80400.0  76500.0  78900.0   438592.0  0.022021   \n",
       "120 2023-06-28  80000.0  80200.0  78100.0  78500.0   246068.0 -0.005070   \n",
       "121 2023-06-29  78900.0  81800.0  76800.0  78400.0   370929.0 -0.001274   \n",
       "122 2023-06-30  78800.0  79800.0  76800.0  76900.0   302507.0 -0.019133   \n",
       "\n",
       "            MACD       Signal          PSAR  ...         OBV            FI  \\\n",
       "0     686.685188   731.113168  42450.000000  ...   2124425.0  6.229637e+09   \n",
       "1     977.776846   780.445904  42450.000000  ...   3301240.0  1.706382e+09   \n",
       "2    1138.856898   852.128103  42784.000000  ...   2795861.0 -3.537653e+08   \n",
       "3    1276.012416   936.904965  43104.640000  ...   3241011.0  1.335450e+08   \n",
       "4    1408.815031  1031.286979  43412.454400  ...   3821148.0  2.900685e+08   \n",
       "..           ...          ...           ...  ...         ...           ...   \n",
       "118  -274.988847  1400.729619  83589.187649  ...  10771841.0 -1.757376e+08   \n",
       "119  -454.030222  1029.777651  82191.350119  ...  11210433.0  7.456064e+08   \n",
       "120  -621.039502   699.614220  81053.080095  ...  10964365.0 -9.842720e+07   \n",
       "121  -752.787063   409.133964  76500.000000  ...  10593436.0 -3.709290e+07   \n",
       "122  -967.087436   133.889684  76606.000000  ...  10290929.0 -4.537605e+08   \n",
       "\n",
       "      keyword  view_log_like_sum  view_log_like_avg  count      trend  DAY  \\\n",
       "0    69.27633       0.000000e+00           0.000000    0.0   4.168034    월   \n",
       "1    60.65854       0.000000e+00           0.000000    0.0   4.105260    화   \n",
       "2    53.81251       0.000000e+00           0.000000    0.0   3.985506    수   \n",
       "3    51.66778       0.000000e+00           0.000000    0.0   3.944834    목   \n",
       "4    45.43369       0.000000e+00           0.000000    0.0   3.816254    금   \n",
       "..        ...                ...                ...    ...        ...  ...   \n",
       "118  36.15345       0.000000e+00           0.000000    0.0   3.558157    월   \n",
       "119  36.76734       2.716231e+06      679057.811532    4.0  17.677466    화   \n",
       "120  37.15977       0.000000e+00           0.000000    0.0   3.615227    수   \n",
       "121  38.06506       0.000000e+00           0.000000    0.0   3.639297    목   \n",
       "122  34.39338       2.938695e+05       73467.376172    4.0  15.386855    금   \n",
       "\n",
       "      SENTIMENT      EVENT  \n",
       "0    126.027702  28.548385  \n",
       "1    119.020563 -33.331533  \n",
       "2    209.513567  74.965736  \n",
       "3    277.915244        NaN  \n",
       "4    269.611104        NaN  \n",
       "..          ...        ...  \n",
       "118  282.396226        NaN  \n",
       "119         NaN        NaN  \n",
       "120         NaN        NaN  \n",
       "121         NaN        NaN  \n",
       "122         NaN        NaN  \n",
       "\n",
       "[124 rows x 26 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변수 이름 변경\n",
    "merged_df = merged_df.rename(columns={'SENTIMENT_SUM_x': 'SENTIMENT', 'SENTIMENT_SUM_y': 'EVENT'})\n",
    "merged_df = merged_df.drop(columns=['DAY', 'DAY_y'])\n",
    "\n",
    "# DAY_x 열을 DAY로 변경\n",
    "merged_df = merged_df.rename(columns={'DAY_x': 'DAY'})\n",
    "\n",
    "# 결과 출력\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f95cb6d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124 entries, 0 to 122\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   DATE               124 non-null    datetime64[ns]\n",
      " 1   Open               123 non-null    float64       \n",
      " 2   High               123 non-null    float64       \n",
      " 3   Low                123 non-null    float64       \n",
      " 4   Close              123 non-null    float64       \n",
      " 5   Volume             123 non-null    float64       \n",
      " 6   Change             123 non-null    float64       \n",
      " 7   MACD               123 non-null    float64       \n",
      " 8   Signal             123 non-null    float64       \n",
      " 9   PSAR               123 non-null    float64       \n",
      " 10  upper              123 non-null    float64       \n",
      " 11  middle             123 non-null    float64       \n",
      " 12  lower              123 non-null    float64       \n",
      " 13  SlowK              123 non-null    float64       \n",
      " 14  SlowD              123 non-null    float64       \n",
      " 15  ROC                123 non-null    float64       \n",
      " 16  OBV                123 non-null    float64       \n",
      " 17  FI                 123 non-null    float64       \n",
      " 18  keyword            123 non-null    float64       \n",
      " 19  view_log_like_sum  123 non-null    float64       \n",
      " 20  view_log_like_avg  123 non-null    float64       \n",
      " 21  count              123 non-null    float64       \n",
      " 22  trend              123 non-null    float64       \n",
      " 23  DAY                123 non-null    object        \n",
      " 24  SENTIMENT          120 non-null    float64       \n",
      " 25  EVENT              17 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(24), object(1)\n",
      "memory usage: 26.2+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "417b22f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Change</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal</th>\n",
       "      <th>PSAR</th>\n",
       "      <th>...</th>\n",
       "      <th>OBV</th>\n",
       "      <th>FI</th>\n",
       "      <th>keyword</th>\n",
       "      <th>view_log_like_sum</th>\n",
       "      <th>view_log_like_avg</th>\n",
       "      <th>count</th>\n",
       "      <th>trend</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.329536</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE  Open  High  Low  Close  Volume  Change  MACD  Signal  PSAR  \\\n",
       "123 2023-05-01   NaN   NaN  NaN    NaN     NaN     NaN   NaN     NaN   NaN   \n",
       "\n",
       "     ...  OBV  FI  keyword  view_log_like_sum  view_log_like_avg  count  \\\n",
       "123  ...  NaN NaN      NaN                NaN                NaN    NaN   \n",
       "\n",
       "     trend  DAY  SENTIMENT  EVENT  \n",
       "123    NaN  NaN  33.329536    NaN  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df['Open'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e63270d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23828/117352557.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[merged_df['DATE'] == '2023-05-02']['EVENT'] = (a+b)/2\n",
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23828/117352557.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[merged_df['DATE'] == '2023-05-02']['SENTIMENT'] = (c+d)/2\n"
     ]
    }
   ],
   "source": [
    "# 제거되지 않은 5월 1일의 데이터를 5월 2일 데이터와 병합\n",
    "a = float(merged_df[merged_df['DATE'] == '2023-05-01']['EVENT'])\n",
    "b = float(merged_df[merged_df['DATE'] == '2023-05-02']['EVENT'])\n",
    "merged_df[merged_df['DATE'] == '2023-05-02']['EVENT'] = (a+b)/2\n",
    "\n",
    "c = float(merged_df[merged_df['DATE'] == '2023-05-01']['SENTIMENT'])\n",
    "d = float(merged_df[merged_df['DATE'] == '2023-05-02']['SENTIMENT'])\n",
    "merged_df[merged_df['DATE'] == '2023-05-02']['SENTIMENT'] = (c+d)/2\n",
    "\n",
    "merged_df = merged_df[merged_df['DATE'] != '2023-05-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80618210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Change</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal</th>\n",
       "      <th>PSAR</th>\n",
       "      <th>...</th>\n",
       "      <th>OBV</th>\n",
       "      <th>FI</th>\n",
       "      <th>keyword</th>\n",
       "      <th>view_log_like_sum</th>\n",
       "      <th>view_log_like_avg</th>\n",
       "      <th>count</th>\n",
       "      <th>trend</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [DATE, Open, High, Low, Close, Volume, Change, MACD, Signal, PSAR, upper, middle, lower, SlowK, SlowD, ROC, OBV, FI, keyword, view_log_like_sum, view_log_like_avg, count, trend, DAY, SENTIMENT, EVENT]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 26 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df['Open'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ab6f3",
   "metadata": {},
   "source": [
    "# CSV 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e73a2dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"../../data/FINALDATA/yg.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "270.885px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
