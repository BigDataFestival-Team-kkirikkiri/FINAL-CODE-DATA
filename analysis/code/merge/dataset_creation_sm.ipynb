{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faf5854d",
   "metadata": {},
   "source": [
    "# 데이터, 패키지 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d487e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 로드 \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "799aba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 \n",
    "df_stock= pd.read_csv(\"../../data/Stock/stock+tech_sm.csv\")\n",
    "df_trend= pd.read_csv(\"../../data/Trend/trend_sm.csv\")\n",
    "df_sentiment= pd.read_excel(\"../../data/News/sentiment_sm.xlsx\")\n",
    "df_event= pd.read_excel(\"../../data/News/event_sm.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "733fa2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123 entries, 0 to 122\n",
      "Data columns (total 18 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Date    123 non-null    object \n",
      " 1   Open    123 non-null    int64  \n",
      " 2   High    123 non-null    int64  \n",
      " 3   Low     123 non-null    int64  \n",
      " 4   Close   123 non-null    int64  \n",
      " 5   Volume  123 non-null    int64  \n",
      " 6   Change  123 non-null    float64\n",
      " 7   MACD    123 non-null    float64\n",
      " 8   Signal  123 non-null    float64\n",
      " 9   PSAR    123 non-null    float64\n",
      " 10  upper   123 non-null    float64\n",
      " 11  middle  123 non-null    float64\n",
      " 12  lower   123 non-null    float64\n",
      " 13  SlowK   123 non-null    float64\n",
      " 14  SlowD   123 non-null    float64\n",
      " 15  ROC     123 non-null    float64\n",
      " 16  OBV     123 non-null    float64\n",
      " 17  FI      123 non-null    float64\n",
      "dtypes: float64(12), int64(5), object(1)\n",
      "memory usage: 17.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_stock.info() # 주가+기술지표 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "248e5e31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 181 entries, 0 to 180\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   date               181 non-null    object \n",
      " 1   keyword            181 non-null    float64\n",
      " 2   view_log_like_sum  181 non-null    float64\n",
      " 3   view_log_like_avg  181 non-null    float64\n",
      " 4   count              181 non-null    float64\n",
      " 5   trend              181 non-null    float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 8.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_trend.info() # 트렌드(유튜브, 네이버) 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c322283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125 entries, 0 to 124\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   DATE           125 non-null    datetime64[ns]\n",
      " 1   SENTIMENT_SUM  125 non-null    float64       \n",
      " 2   DAY            125 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 3.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_sentiment.info() # 감정지수(뉴스) 변수 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f7b9201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42 entries, 0 to 41\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   DATE           42 non-null     datetime64[ns]\n",
      " 1   SENTIMENT_SUM  42 non-null     float64       \n",
      " 2   DAY            42 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 1.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_event.info() # 이벤트 변수 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab74d0d3",
   "metadata": {},
   "source": [
    "# DATE 변수타입 통일 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4192c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stock의 'Date' 열을 datetime 형식으로 변환\n",
    "df_stock['Date'] = pd.to_datetime(df_stock['Date'])\n",
    "\n",
    "# df_trend의 'date' 열을 datetime 형식으로 변환\n",
    "df_trend['date'] = pd.to_datetime(df_trend['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b851b1",
   "metadata": {},
   "source": [
    "# DATE 변수명 통일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b8abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stock의'Date' 열의 이름을 'DATE'로 변경\n",
    "df_stock = df_stock.rename(columns={'Date': 'DATE'})\n",
    "\n",
    "# df_trend의'date' 열의 이름을 'DATE'로 변경\n",
    "df_trend = df_trend.rename(columns={'date': 'DATE'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f915074",
   "metadata": {},
   "source": [
    "# df_trend 데이터의 DATE 수정 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11f3f1a",
   "metadata": {},
   "source": [
    "### 일자별 요일 지정\n",
    "향후 분석에 용이하도록 DATE_NEW 일자를 기준으로 일자별 요일을 지정해줌.\n",
    "- 2023년 1월은 일요일부터 시작함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aa1d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_dict = {0:'월', 1:'화', 2:'수', 3:'목', 4:'금', 5:'토', 6:'일'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6cf7693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAY\n",
       "금    26\n",
       "목    26\n",
       "수    26\n",
       "월    26\n",
       "일    26\n",
       "토    25\n",
       "화    26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_list = []\n",
    "\n",
    "for i in range(len(df_trend)):\n",
    "    day_list.append(weekday_dict[df_trend[\"DATE\"][i].weekday()])\n",
    "\n",
    "df_trend[\"DAY\"] = day_list\n",
    "df_trend.groupby(\"DAY\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d26645d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "월 ['2023-01-02T00:00:00.000000000' '2023-01-09T00:00:00.000000000'\n",
      " '2023-01-16T00:00:00.000000000' '2023-01-23T00:00:00.000000000'\n",
      " '2023-01-30T00:00:00.000000000' '2023-02-06T00:00:00.000000000'\n",
      " '2023-02-13T00:00:00.000000000' '2023-02-20T00:00:00.000000000'\n",
      " '2023-02-27T00:00:00.000000000' '2023-03-06T00:00:00.000000000'\n",
      " '2023-03-13T00:00:00.000000000' '2023-03-20T00:00:00.000000000'\n",
      " '2023-03-27T00:00:00.000000000' '2023-04-03T00:00:00.000000000'\n",
      " '2023-04-10T00:00:00.000000000' '2023-04-17T00:00:00.000000000'\n",
      " '2023-04-24T00:00:00.000000000' '2023-05-01T00:00:00.000000000'\n",
      " '2023-05-08T00:00:00.000000000' '2023-05-15T00:00:00.000000000'\n",
      " '2023-05-22T00:00:00.000000000' '2023-05-29T00:00:00.000000000'\n",
      " '2023-06-05T00:00:00.000000000' '2023-06-12T00:00:00.000000000'\n",
      " '2023-06-19T00:00:00.000000000' '2023-06-26T00:00:00.000000000']\n",
      "화 ['2023-01-03T00:00:00.000000000' '2023-01-10T00:00:00.000000000'\n",
      " '2023-01-17T00:00:00.000000000' '2023-01-24T00:00:00.000000000'\n",
      " '2023-01-31T00:00:00.000000000' '2023-02-07T00:00:00.000000000'\n",
      " '2023-02-14T00:00:00.000000000' '2023-02-21T00:00:00.000000000'\n",
      " '2023-02-28T00:00:00.000000000' '2023-03-07T00:00:00.000000000'\n",
      " '2023-03-14T00:00:00.000000000' '2023-03-21T00:00:00.000000000'\n",
      " '2023-03-28T00:00:00.000000000' '2023-04-04T00:00:00.000000000'\n",
      " '2023-04-11T00:00:00.000000000' '2023-04-18T00:00:00.000000000'\n",
      " '2023-04-25T00:00:00.000000000' '2023-05-02T00:00:00.000000000'\n",
      " '2023-05-09T00:00:00.000000000' '2023-05-16T00:00:00.000000000'\n",
      " '2023-05-23T00:00:00.000000000' '2023-05-30T00:00:00.000000000'\n",
      " '2023-06-06T00:00:00.000000000' '2023-06-13T00:00:00.000000000'\n",
      " '2023-06-20T00:00:00.000000000' '2023-06-27T00:00:00.000000000']\n",
      "수 ['2023-01-04T00:00:00.000000000' '2023-01-11T00:00:00.000000000'\n",
      " '2023-01-18T00:00:00.000000000' '2023-01-25T00:00:00.000000000'\n",
      " '2023-02-01T00:00:00.000000000' '2023-02-08T00:00:00.000000000'\n",
      " '2023-02-15T00:00:00.000000000' '2023-02-22T00:00:00.000000000'\n",
      " '2023-03-01T00:00:00.000000000' '2023-03-08T00:00:00.000000000'\n",
      " '2023-03-15T00:00:00.000000000' '2023-03-22T00:00:00.000000000'\n",
      " '2023-03-29T00:00:00.000000000' '2023-04-05T00:00:00.000000000'\n",
      " '2023-04-12T00:00:00.000000000' '2023-04-19T00:00:00.000000000'\n",
      " '2023-04-26T00:00:00.000000000' '2023-05-03T00:00:00.000000000'\n",
      " '2023-05-10T00:00:00.000000000' '2023-05-17T00:00:00.000000000'\n",
      " '2023-05-24T00:00:00.000000000' '2023-05-31T00:00:00.000000000'\n",
      " '2023-06-07T00:00:00.000000000' '2023-06-14T00:00:00.000000000'\n",
      " '2023-06-21T00:00:00.000000000' '2023-06-28T00:00:00.000000000']\n",
      "목 ['2023-01-05T00:00:00.000000000' '2023-01-12T00:00:00.000000000'\n",
      " '2023-01-19T00:00:00.000000000' '2023-01-26T00:00:00.000000000'\n",
      " '2023-02-02T00:00:00.000000000' '2023-02-09T00:00:00.000000000'\n",
      " '2023-02-16T00:00:00.000000000' '2023-02-23T00:00:00.000000000'\n",
      " '2023-03-02T00:00:00.000000000' '2023-03-09T00:00:00.000000000'\n",
      " '2023-03-16T00:00:00.000000000' '2023-03-23T00:00:00.000000000'\n",
      " '2023-03-30T00:00:00.000000000' '2023-04-06T00:00:00.000000000'\n",
      " '2023-04-13T00:00:00.000000000' '2023-04-20T00:00:00.000000000'\n",
      " '2023-04-27T00:00:00.000000000' '2023-05-04T00:00:00.000000000'\n",
      " '2023-05-11T00:00:00.000000000' '2023-05-18T00:00:00.000000000'\n",
      " '2023-05-25T00:00:00.000000000' '2023-06-01T00:00:00.000000000'\n",
      " '2023-06-08T00:00:00.000000000' '2023-06-15T00:00:00.000000000'\n",
      " '2023-06-22T00:00:00.000000000' '2023-06-29T00:00:00.000000000']\n",
      "금 ['2023-01-06T00:00:00.000000000' '2023-01-13T00:00:00.000000000'\n",
      " '2023-01-20T00:00:00.000000000' '2023-01-27T00:00:00.000000000'\n",
      " '2023-02-03T00:00:00.000000000' '2023-02-10T00:00:00.000000000'\n",
      " '2023-02-17T00:00:00.000000000' '2023-02-24T00:00:00.000000000'\n",
      " '2023-03-03T00:00:00.000000000' '2023-03-10T00:00:00.000000000'\n",
      " '2023-03-17T00:00:00.000000000' '2023-03-24T00:00:00.000000000'\n",
      " '2023-03-31T00:00:00.000000000' '2023-04-07T00:00:00.000000000'\n",
      " '2023-04-14T00:00:00.000000000' '2023-04-21T00:00:00.000000000'\n",
      " '2023-04-28T00:00:00.000000000' '2023-05-05T00:00:00.000000000'\n",
      " '2023-05-12T00:00:00.000000000' '2023-05-19T00:00:00.000000000'\n",
      " '2023-05-26T00:00:00.000000000' '2023-06-02T00:00:00.000000000'\n",
      " '2023-06-09T00:00:00.000000000' '2023-06-16T00:00:00.000000000'\n",
      " '2023-06-23T00:00:00.000000000' '2023-06-30T00:00:00.000000000']\n",
      "토 ['2023-01-07T00:00:00.000000000' '2023-01-14T00:00:00.000000000'\n",
      " '2023-01-21T00:00:00.000000000' '2023-01-28T00:00:00.000000000'\n",
      " '2023-02-04T00:00:00.000000000' '2023-02-11T00:00:00.000000000'\n",
      " '2023-02-18T00:00:00.000000000' '2023-02-25T00:00:00.000000000'\n",
      " '2023-03-04T00:00:00.000000000' '2023-03-11T00:00:00.000000000'\n",
      " '2023-03-18T00:00:00.000000000' '2023-03-25T00:00:00.000000000'\n",
      " '2023-04-01T00:00:00.000000000' '2023-04-08T00:00:00.000000000'\n",
      " '2023-04-15T00:00:00.000000000' '2023-04-22T00:00:00.000000000'\n",
      " '2023-04-29T00:00:00.000000000' '2023-05-06T00:00:00.000000000'\n",
      " '2023-05-13T00:00:00.000000000' '2023-05-20T00:00:00.000000000'\n",
      " '2023-05-27T00:00:00.000000000' '2023-06-03T00:00:00.000000000'\n",
      " '2023-06-10T00:00:00.000000000' '2023-06-17T00:00:00.000000000'\n",
      " '2023-06-24T00:00:00.000000000']\n",
      "일 ['2023-01-01T00:00:00.000000000' '2023-01-08T00:00:00.000000000'\n",
      " '2023-01-15T00:00:00.000000000' '2023-01-22T00:00:00.000000000'\n",
      " '2023-01-29T00:00:00.000000000' '2023-02-05T00:00:00.000000000'\n",
      " '2023-02-12T00:00:00.000000000' '2023-02-19T00:00:00.000000000'\n",
      " '2023-02-26T00:00:00.000000000' '2023-03-05T00:00:00.000000000'\n",
      " '2023-03-12T00:00:00.000000000' '2023-03-19T00:00:00.000000000'\n",
      " '2023-03-26T00:00:00.000000000' '2023-04-02T00:00:00.000000000'\n",
      " '2023-04-09T00:00:00.000000000' '2023-04-16T00:00:00.000000000'\n",
      " '2023-04-23T00:00:00.000000000' '2023-04-30T00:00:00.000000000'\n",
      " '2023-05-07T00:00:00.000000000' '2023-05-14T00:00:00.000000000'\n",
      " '2023-05-21T00:00:00.000000000' '2023-05-28T00:00:00.000000000'\n",
      " '2023-06-04T00:00:00.000000000' '2023-06-11T00:00:00.000000000'\n",
      " '2023-06-18T00:00:00.000000000' '2023-06-25T00:00:00.000000000']\n"
     ]
    }
   ],
   "source": [
    "#요일 배정이 잘 되었는지 확인\n",
    "for day in weekday_dict.values():\n",
    "    print(day, df_trend[df_trend[\"DAY\"] == day][\"DATE\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a788ac6",
   "metadata": {},
   "source": [
    "- **설명**\n",
    "- '요일' 변수는 각 뉴스가 영향을 미치는 요일을 의미한다 \n",
    "- ex1) 요일이 '금'으로 지정된 데이터 : 금요일 주가에 영향을 미치는 데이터 \n",
    "- ex2) 요일이 '토'으로 지정된 데이터 : 금요일 주가에 영향을 미치는 데이터 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee1522",
   "metadata": {},
   "source": [
    "* **토요일, 일요일 데이터 전처리**\n",
    "- 토요일과 일요일 데이터는 ***월요일*** 주가에 영향을 미친다\n",
    "- 따라서 요일 변수가 토요일, 일요일로 설정된 데이터들은 그 다음주 월요일 데이터로 간주하여 날짜 및 요일 변수를 변경한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36b20a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23827/3245083037.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend['DATE'].iloc[i]+= datetime.timedelta(days=1)  # DATE_NEW(날짜)변수에 하루를 추가\n",
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23827/3245083037.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend['DAY'].iloc[i] = '월'       #DAY(요일) 변수를 월요일로\n",
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23827/3245083037.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend['DATE'].iloc[i]+= datetime.timedelta(days=2)  # DATE_NEW(날짜)변수에 이틀을 추가\n",
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23827/3245083037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend['DAY'].iloc[i] = '월'       #DAY(요일) 변수를 월요일로\n"
     ]
    }
   ],
   "source": [
    " for i in range(len(df_trend)):\n",
    "    if (df_trend['DAY'].iloc[i] == '토'): # 토요일 뉴스기사라면, \n",
    "        df_trend['DATE'].iloc[i]+= datetime.timedelta(days=2)  # DATE_NEW(날짜)변수에 이틀을 추가\n",
    "        df_trend['DAY'].iloc[i] = '월'       #DAY(요일) 변수를 월요일로\n",
    "    if (df_trend['DAY'].iloc[i] == '일'): # 일요일 뉴스기사라면, \n",
    "        df_trend['DATE'].iloc[i]+= datetime.timedelta(days=1)  # DATE_NEW(날짜)변수에 하루를 추가\n",
    "        df_trend['DAY'].iloc[i] = '월'       #DAY(요일) 변수를 월요일로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d37bb44",
   "metadata": {},
   "source": [
    "### 월요일 데이터들의 변수 값 평균 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221a8008",
   "metadata": {},
   "source": [
    "- df_trend에서 DAY 변수의 값이 '월'인 행들은 DATE 변수로 GROUPBY 한 뒤 keyword, view_log_like_sum, view_log_like_avg, count, trend 변수의 평균값을 구할 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05fe83ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>keyword</th>\n",
       "      <th>view_log_like_sum</th>\n",
       "      <th>view_log_like_avg</th>\n",
       "      <th>count</th>\n",
       "      <th>trend</th>\n",
       "      <th>DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>24.96469</td>\n",
       "      <td>1.511554e+08</td>\n",
       "      <td>3.023108e+07</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>12.280464</td>\n",
       "      <td>월</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>14.64458</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.660563</td>\n",
       "      <td>월</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-16</td>\n",
       "      <td>14.44341</td>\n",
       "      <td>8.408403e+07</td>\n",
       "      <td>7.676136e+07</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>19.963843</td>\n",
       "      <td>월</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>16.27777</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.664408</td>\n",
       "      <td>월</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>13.87243</td>\n",
       "      <td>1.193401e+08</td>\n",
       "      <td>1.193401e+08</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>14.888487</td>\n",
       "      <td>월</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE   keyword  view_log_like_sum  view_log_like_avg     count  \\\n",
       "0 2023-01-02  24.96469       1.511554e+08       3.023108e+07  2.500000   \n",
       "1 2023-01-09  14.64458       0.000000e+00       0.000000e+00  0.000000   \n",
       "2 2023-01-16  14.44341       8.408403e+07       7.676136e+07  2.333333   \n",
       "3 2023-01-23  16.27777       0.000000e+00       0.000000e+00  0.000000   \n",
       "4 2023-01-30  13.87243       1.193401e+08       1.193401e+08  0.666667   \n",
       "\n",
       "       trend DAY  \n",
       "0  12.280464   월  \n",
       "1   2.660563   월  \n",
       "2  19.963843   월  \n",
       "3   2.664408   월  \n",
       "4  14.888487   월  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'DAY' 변수가 '월'인 행 필터링\n",
    "df_trend_monday = df_trend[df_trend['DAY'] == '월']\n",
    "df_trend_notmonday = df_trend[df_trend['DAY'] != '월']\n",
    "\n",
    "# 'DATE' 변수로 그룹화하여 변수들의 평균값 구하기\n",
    "df_trend_monday = df_trend_monday.groupby('DATE').agg({\n",
    "    'keyword': 'first',  # 첫 번째 키워드 선택\n",
    "    'view_log_like_sum': 'mean',\n",
    "    'view_log_like_avg': 'mean',\n",
    "    'count': 'mean',\n",
    "    'trend': 'mean',\n",
    "    'DAY': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# 결과 출력\n",
    "df_trend_monday.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66815cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 월요일 데이터, 월요일이 아닌 데이터 다시 합치기 \n",
    "df_trend = pd.concat([df_trend_monday, df_trend_notmonday], axis=0)\n",
    "\n",
    "# 행 인덱스 초기화\n",
    "df_trend = df_trend.reset_index(drop=True)\n",
    "\n",
    "# 'DATE' 변수로 정렬\n",
    "df_trend = df_trend.sort_values(by='DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "874a6b12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE                 130\n",
       "keyword              130\n",
       "view_log_like_sum     82\n",
       "view_log_like_avg     82\n",
       "count                 27\n",
       "trend                130\n",
       "DAY                    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trend.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755e161b",
   "metadata": {},
   "source": [
    "# df_trend, df_sentiment, df_event 의 날짜 변수를 df_stock 에 맞추기 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c129280",
   "metadata": {},
   "source": [
    "##  df_stock와 df_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "581d7ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_trend와 df_stock의 'DATE' 열에서 다른 원소:\n",
      "{Timestamp('2023-05-29 00:00:00'), Timestamp('2023-03-01 00:00:00'), Timestamp('2023-05-01 00:00:00'), Timestamp('2023-05-05 00:00:00'), Timestamp('2023-06-06 00:00:00'), Timestamp('2023-01-23 00:00:00'), Timestamp('2023-01-24 00:00:00')}\n"
     ]
    }
   ],
   "source": [
    "set_trend_dates = set(df_trend['DATE'])\n",
    "set_stock_dates = set(df_stock['DATE'])\n",
    "\n",
    "# 차이를 확인하여 다른 원소를 추출\n",
    "difference = set_trend_dates.symmetric_difference(set_stock_dates)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"df_trend와 df_stock의 'DATE' 열에서 다른 원소:\")\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5032aab1",
   "metadata": {},
   "source": [
    "- 1/23 : 설 연휴\n",
    "- 1/24 : 설 연휴 \n",
    "- 3/1 : 삼일절\n",
    "- 5/1 : 노동절\n",
    "- 5/5 : 어린이날\n",
    "- 5/29 : 석가탄신일\n",
    "- 6/6 : 현충일 \n",
    "- 해당 일자들은 주식 시장이 개장하지 않는 일자임\n",
    "- 따라서 df_trend 에서 1/23, 1/24, 1/25에 대한 변수들의 값을 더한 뒤 평균을 내주는 식의 방법을 사용함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fc2d977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1월 23일, 1월 24일, 1월 25일 데이터 필터링\n",
    "selected_dates = ['2023-01-23', '2023-01-24', '2023-01-25']\n",
    "filtered_df = df_trend[df_trend['DATE'].isin(selected_dates)]\n",
    "\n",
    "# 1월 23일, 1월 24일 데이터 삭제\n",
    "df_trend = df_trend[df_trend['DATE'] != '2023-01-23']\n",
    "df_trend = df_trend[df_trend['DATE'] != '2023-01-24']\n",
    "\n",
    "# 1월 25일 데이터를 평균값으로 대체\n",
    "average_values = filtered_df.mean(numeric_only = True)\n",
    "df_trend.loc[df_trend['DATE'] == '2023-01-25', ['keyword', 'view_log_like_sum', 'view_log_like_avg', 'count', 'trend']] = average_values.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb2e023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업할 날짜 쌍 정의\n",
    "date_pairs = [('2023-03-01', '2023-03-02'), ('2023-05-01', '2023-05-02'), ('2023-05-05', '2023-05-08'), ('2023-05-29', '2023-05-30'), ('2023-06-06', '2023-06-07')]\n",
    "\n",
    "# 날짜 쌍에 대한 반복 작업\n",
    "for start_date, end_date in date_pairs:\n",
    "    # 선택한 날짜 데이터 필터링\n",
    "    selected_dates = [start_date, end_date]\n",
    "    filtered_df = df_trend[df_trend['DATE'].isin(selected_dates)]\n",
    "\n",
    "    # 시작 날짜 데이터 삭제\n",
    "    df_trend = df_trend[df_trend['DATE'] != start_date]\n",
    "\n",
    "    # 끝 날짜 데이터를 평균값으로 대체\n",
    "    average_values = filtered_df.mean(numeric_only = True)\n",
    "    df_trend.loc[df_trend['DATE'] == end_date, ['keyword', 'view_log_like_sum', 'view_log_like_avg', 'count', 'trend']] = average_values[['keyword', 'view_log_like_sum', 'view_log_like_avg', 'count', 'trend']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b56db8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_trend와 df_stock의 'DATE' 열에서 다른 원소:\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# 차이 없는지 확인\n",
    "\n",
    "set_trend_dates = set(df_trend['DATE'])\n",
    "set_stock_dates = set(df_stock['DATE'])\n",
    "\n",
    "# 차이를 확인하여 다른 원소를 추출\n",
    "difference = set_trend_dates.symmetric_difference(set_stock_dates)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"df_trend와 df_stock의 'DATE' 열에서 다른 원소:\")\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaa262f",
   "metadata": {},
   "source": [
    "##  df_stock와 df_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2049be88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_sentiment_dates df_stock의 'DATE' 열에서 다른 원소:\n",
      "{Timestamp('2023-05-29 00:00:00'), Timestamp('2023-03-01 00:00:00'), Timestamp('2023-06-28 00:00:00'), Timestamp('2023-05-01 00:00:00'), Timestamp('2023-04-05 00:00:00'), Timestamp('2023-05-05 00:00:00'), Timestamp('2023-06-06 00:00:00'), Timestamp('2023-06-30 00:00:00'), Timestamp('2023-01-23 00:00:00'), Timestamp('2023-01-24 00:00:00'), Timestamp('2023-06-29 00:00:00'), Timestamp('2023-06-27 00:00:00')}\n"
     ]
    }
   ],
   "source": [
    "set_sentiment_dates = set(df_sentiment['DATE'])\n",
    "set_stock_dates = set(df_stock['DATE'])\n",
    "\n",
    "# 차이를 확인하여 다른 원소를 추출\n",
    "difference = set_sentiment_dates.symmetric_difference(set_stock_dates)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"set_sentiment_dates df_stock의 'DATE' 열에서 다른 원소:\")\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d219d97",
   "metadata": {},
   "source": [
    "- 1/23 : 설 연휴\n",
    "- 1/24 : 설 연휴 \n",
    "- 3/1 : 삼일절\n",
    "- 5/5 : 어린이날\n",
    "- 6/6 : 현충일 \n",
    "- 해당 일자들은 주식 시장이 개장하지 않는 일자임\n",
    "- 따라서 df_trend 에서 1/23, 1/24, 1/25에 대한 변수들의 값을 더한 뒤 평균을 내주는 식의 방법을 사용함 \n",
    "\n",
    "- 4/5 : \n",
    "- 6/27 : \n",
    "- 6/28 :  \n",
    "- 6/29 : \n",
    "- 6/30 : \n",
    "- 해당 일자들은 df_sentiment 값이 존재하지 않는(영상 등이 올라오지 않은) 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de6b5e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1월 23일, 1월 24일, 1월 25일 데이터 필터링\n",
    "selected_dates = ['2023-01-23', '2023-01-24', '2023-01-25']\n",
    "filtered_df = df_sentiment[df_sentiment['DATE'].isin(selected_dates)]\n",
    "\n",
    "# 1월 23일, 1월 24일 데이터 삭제\n",
    "df_sentiment = df_sentiment[df_sentiment['DATE'] != '2023-01-23']\n",
    "df_sentiment = df_sentiment[df_sentiment['DATE'] != '2023-01-24']\n",
    "\n",
    "# 1월 25일 데이터를 평균값으로 대체\n",
    "average_values = filtered_df.mean(numeric_only = True)\n",
    "df_sentiment.loc[df_sentiment['DATE'] == '2023-01-25', 'SENTIMENT_SUM'] = average_values.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9f75684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업할 날짜 쌍 정의\n",
    "date_pairs = [('2023-03-01', '2023-03-02'), ('2023-05-05', '2023-05-08'), ('2023-06-06', '2023-06-07')]\n",
    "\n",
    "# 날짜 쌍에 대한 반복 작업\n",
    "for start_date, end_date in date_pairs:\n",
    "    # 선택한 날짜 데이터 필터링\n",
    "    selected_dates = [start_date, end_date]\n",
    "    filtered_df = df_sentiment[df_sentiment['DATE'].isin(selected_dates)]\n",
    "\n",
    "    # 시작 날짜 데이터 삭제\n",
    "    df_sentiment = df_sentiment[df_sentiment['DATE'] != start_date]\n",
    "\n",
    "    # 끝 날짜 데이터를 평균값으로 대체\n",
    "    average_values = filtered_df.mean(numeric_only = True)\n",
    "    df_sentiment.loc[df_sentiment['DATE'] == end_date, 'SENTIMENT_SUM'] = average_values.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bab24e9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_sentiment와 df_stock의 'DATE' 열에서 다른 원소:\n",
      "{Timestamp('2023-05-29 00:00:00'), Timestamp('2023-06-28 00:00:00'), Timestamp('2023-05-01 00:00:00'), Timestamp('2023-04-05 00:00:00'), Timestamp('2023-06-30 00:00:00'), Timestamp('2023-06-29 00:00:00'), Timestamp('2023-06-27 00:00:00')}\n"
     ]
    }
   ],
   "source": [
    "# 결측치를 제외하고 차이 없는지 확인\n",
    "\n",
    "set_sentiment_dates = set(df_sentiment['DATE'])\n",
    "set_stock_dates = set(df_stock['DATE'])\n",
    "\n",
    "# 차이를 확인하여 다른 원소를 추출\n",
    "difference = set_sentiment_dates.symmetric_difference(set_stock_dates)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"df_sentiment와 df_stock의 'DATE' 열에서 다른 원소:\")\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b163b8d8",
   "metadata": {},
   "source": [
    "# DATE 기준으로 데이터프레임 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ba61eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "123\n",
      "120\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "print(df_stock['DATE'].nunique())\n",
    "print(df_trend['DATE'].nunique())\n",
    "print(df_sentiment['DATE'].nunique())\n",
    "print(df_event['DATE'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1303efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 병합\n",
    "merged_df = df_stock.merge(df_trend, on='DATE', how='outer')\n",
    "merged_df = merged_df.merge(df_sentiment, on='DATE', how='outer')\n",
    "merged_df = merged_df.merge(df_event, on='DATE', how='outer')\n",
    "\n",
    "# 날짜로 정렬\n",
    "merged_df['DATE'] = pd.to_datetime(merged_df['DATE'])\n",
    "merged_df = merged_df.sort_values(by='DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38445945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Change</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal</th>\n",
       "      <th>PSAR</th>\n",
       "      <th>...</th>\n",
       "      <th>keyword</th>\n",
       "      <th>view_log_like_sum</th>\n",
       "      <th>view_log_like_avg</th>\n",
       "      <th>count</th>\n",
       "      <th>trend</th>\n",
       "      <th>DAY_x</th>\n",
       "      <th>SENTIMENT_SUM_x</th>\n",
       "      <th>DAY_y</th>\n",
       "      <th>SENTIMENT_SUM_y</th>\n",
       "      <th>DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>73300.0</td>\n",
       "      <td>75200.0</td>\n",
       "      <td>425582.0</td>\n",
       "      <td>-0.019557</td>\n",
       "      <td>1117.160676</td>\n",
       "      <td>2197.145019</td>\n",
       "      <td>81365.440000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.96469</td>\n",
       "      <td>1.511554e+08</td>\n",
       "      <td>3.023108e+07</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>12.280464</td>\n",
       "      <td>월</td>\n",
       "      <td>80.773832</td>\n",
       "      <td>월</td>\n",
       "      <td>24.993916</td>\n",
       "      <td>월</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>74900.0</td>\n",
       "      <td>78400.0</td>\n",
       "      <td>74700.0</td>\n",
       "      <td>77200.0</td>\n",
       "      <td>462240.0</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>998.004622</td>\n",
       "      <td>1957.316939</td>\n",
       "      <td>80881.513600</td>\n",
       "      <td>...</td>\n",
       "      <td>14.15332</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.649949</td>\n",
       "      <td>화</td>\n",
       "      <td>181.916077</td>\n",
       "      <td>화</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>77200.0</td>\n",
       "      <td>77400.0</td>\n",
       "      <td>74200.0</td>\n",
       "      <td>75200.0</td>\n",
       "      <td>337977.0</td>\n",
       "      <td>-0.025907</td>\n",
       "      <td>733.731308</td>\n",
       "      <td>1712.599813</td>\n",
       "      <td>80426.622784</td>\n",
       "      <td>...</td>\n",
       "      <td>14.04271</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.642103</td>\n",
       "      <td>수</td>\n",
       "      <td>21.082685</td>\n",
       "      <td>수</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>75600.0</td>\n",
       "      <td>76900.0</td>\n",
       "      <td>73600.0</td>\n",
       "      <td>74400.0</td>\n",
       "      <td>297806.0</td>\n",
       "      <td>-0.010638</td>\n",
       "      <td>454.500292</td>\n",
       "      <td>1460.979909</td>\n",
       "      <td>79999.025417</td>\n",
       "      <td>...</td>\n",
       "      <td>13.70464</td>\n",
       "      <td>1.137340e+06</td>\n",
       "      <td>1.137340e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.834451</td>\n",
       "      <td>목</td>\n",
       "      <td>277.915244</td>\n",
       "      <td>목</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>74000.0</td>\n",
       "      <td>74400.0</td>\n",
       "      <td>71700.0</td>\n",
       "      <td>73900.0</td>\n",
       "      <td>441861.0</td>\n",
       "      <td>-0.006720</td>\n",
       "      <td>190.664023</td>\n",
       "      <td>1206.916732</td>\n",
       "      <td>79597.083892</td>\n",
       "      <td>...</td>\n",
       "      <td>14.24473</td>\n",
       "      <td>2.964739e+06</td>\n",
       "      <td>2.964739e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.831200</td>\n",
       "      <td>금</td>\n",
       "      <td>318.234971</td>\n",
       "      <td>금</td>\n",
       "      <td>0.065548</td>\n",
       "      <td>금</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2023-06-26</td>\n",
       "      <td>110300.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>109400.0</td>\n",
       "      <td>109700.0</td>\n",
       "      <td>193953.0</td>\n",
       "      <td>-0.011712</td>\n",
       "      <td>2278.430780</td>\n",
       "      <td>2139.225965</td>\n",
       "      <td>107945.212075</td>\n",
       "      <td>...</td>\n",
       "      <td>16.79784</td>\n",
       "      <td>1.151153e+08</td>\n",
       "      <td>1.151153e+08</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>14.511251</td>\n",
       "      <td>월</td>\n",
       "      <td>94.132075</td>\n",
       "      <td>월</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2023-06-27</td>\n",
       "      <td>108600.0</td>\n",
       "      <td>110900.0</td>\n",
       "      <td>106400.0</td>\n",
       "      <td>109700.0</td>\n",
       "      <td>238510.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1879.125841</td>\n",
       "      <td>2087.205941</td>\n",
       "      <td>124300.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.64082</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.683814</td>\n",
       "      <td>화</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2023-06-28</td>\n",
       "      <td>109100.0</td>\n",
       "      <td>110200.0</td>\n",
       "      <td>107300.0</td>\n",
       "      <td>107300.0</td>\n",
       "      <td>213378.0</td>\n",
       "      <td>-0.021878</td>\n",
       "      <td>1353.412560</td>\n",
       "      <td>1940.447265</td>\n",
       "      <td>123942.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.29111</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.727272</td>\n",
       "      <td>수</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2023-06-29</td>\n",
       "      <td>107400.0</td>\n",
       "      <td>110500.0</td>\n",
       "      <td>105300.0</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>258872.0</td>\n",
       "      <td>-0.002796</td>\n",
       "      <td>902.173807</td>\n",
       "      <td>1732.792573</td>\n",
       "      <td>123591.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.00185</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.708174</td>\n",
       "      <td>목</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>108800.0</td>\n",
       "      <td>105200.0</td>\n",
       "      <td>106800.0</td>\n",
       "      <td>202510.0</td>\n",
       "      <td>-0.001869</td>\n",
       "      <td>522.403572</td>\n",
       "      <td>1490.714773</td>\n",
       "      <td>122859.513600</td>\n",
       "      <td>...</td>\n",
       "      <td>16.08035</td>\n",
       "      <td>1.563737e+08</td>\n",
       "      <td>3.127473e+07</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.750628</td>\n",
       "      <td>금</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE      Open      High       Low     Close    Volume    Change  \\\n",
       "0   2023-01-02   77300.0   78000.0   73300.0   75200.0  425582.0 -0.019557   \n",
       "1   2023-01-03   74900.0   78400.0   74700.0   77200.0  462240.0  0.026596   \n",
       "2   2023-01-04   77200.0   77400.0   74200.0   75200.0  337977.0 -0.025907   \n",
       "3   2023-01-05   75600.0   76900.0   73600.0   74400.0  297806.0 -0.010638   \n",
       "4   2023-01-06   74000.0   74400.0   71700.0   73900.0  441861.0 -0.006720   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "118 2023-06-26  110300.0  112000.0  109400.0  109700.0  193953.0 -0.011712   \n",
       "119 2023-06-27  108600.0  110900.0  106400.0  109700.0  238510.0  0.000000   \n",
       "120 2023-06-28  109100.0  110200.0  107300.0  107300.0  213378.0 -0.021878   \n",
       "121 2023-06-29  107400.0  110500.0  105300.0  107000.0  258872.0 -0.002796   \n",
       "122 2023-06-30  107000.0  108800.0  105200.0  106800.0  202510.0 -0.001869   \n",
       "\n",
       "            MACD       Signal           PSAR  ...   keyword  \\\n",
       "0    1117.160676  2197.145019   81365.440000  ...  24.96469   \n",
       "1     998.004622  1957.316939   80881.513600  ...  14.15332   \n",
       "2     733.731308  1712.599813   80426.622784  ...  14.04271   \n",
       "3     454.500292  1460.979909   79999.025417  ...  13.70464   \n",
       "4     190.664023  1206.916732   79597.083892  ...  14.24473   \n",
       "..           ...          ...            ...  ...       ...   \n",
       "118  2278.430780  2139.225965  107945.212075  ...  16.79784   \n",
       "119  1879.125841  2087.205941  124300.000000  ...  14.64082   \n",
       "120  1353.412560  1940.447265  123942.000000  ...  15.29111   \n",
       "121   902.173807  1732.792573  123591.160000  ...  15.00185   \n",
       "122   522.403572  1490.714773  122859.513600  ...  16.08035   \n",
       "\n",
       "     view_log_like_sum  view_log_like_avg     count      trend  DAY_x  \\\n",
       "0         1.511554e+08       3.023108e+07  2.500000  12.280464      월   \n",
       "1         0.000000e+00       0.000000e+00  0.000000   2.649949      화   \n",
       "2         0.000000e+00       0.000000e+00  0.000000   2.642103      수   \n",
       "3         1.137340e+06       1.137340e+06  1.000000  16.834451      목   \n",
       "4         2.964739e+06       2.964739e+06  1.000000  17.831200      금   \n",
       "..                 ...                ...       ...        ...    ...   \n",
       "118       1.151153e+08       1.151153e+08  0.666667  14.511251      월   \n",
       "119       0.000000e+00       0.000000e+00  0.000000   2.683814      화   \n",
       "120       0.000000e+00       0.000000e+00  0.000000   2.727272      수   \n",
       "121       0.000000e+00       0.000000e+00  0.000000   2.708174      목   \n",
       "122       1.563737e+08       3.127473e+07  5.000000  20.750628      금   \n",
       "\n",
       "     SENTIMENT_SUM_x  DAY_y  SENTIMENT_SUM_y  DAY  \n",
       "0          80.773832      월        24.993916    월  \n",
       "1         181.916077      화              NaN  NaN  \n",
       "2          21.082685      수              NaN  NaN  \n",
       "3         277.915244      목              NaN  NaN  \n",
       "4         318.234971      금         0.065548    금  \n",
       "..               ...    ...              ...  ...  \n",
       "118        94.132075      월              NaN  NaN  \n",
       "119              NaN    NaN              NaN  NaN  \n",
       "120              NaN    NaN              NaN  NaN  \n",
       "121              NaN    NaN              NaN  NaN  \n",
       "122              NaN    NaN              NaN  NaN  \n",
       "\n",
       "[127 rows x 28 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d95d9ffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Change</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal</th>\n",
       "      <th>PSAR</th>\n",
       "      <th>...</th>\n",
       "      <th>OBV</th>\n",
       "      <th>FI</th>\n",
       "      <th>keyword</th>\n",
       "      <th>view_log_like_sum</th>\n",
       "      <th>view_log_like_avg</th>\n",
       "      <th>count</th>\n",
       "      <th>trend</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>73300.0</td>\n",
       "      <td>75200.0</td>\n",
       "      <td>425582.0</td>\n",
       "      <td>-0.019557</td>\n",
       "      <td>1117.160676</td>\n",
       "      <td>2197.145019</td>\n",
       "      <td>81365.440000</td>\n",
       "      <td>...</td>\n",
       "      <td>5768696.0</td>\n",
       "      <td>-638373000.0</td>\n",
       "      <td>24.96469</td>\n",
       "      <td>1.511554e+08</td>\n",
       "      <td>3.023108e+07</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>12.280464</td>\n",
       "      <td>월</td>\n",
       "      <td>80.773832</td>\n",
       "      <td>24.993916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>74900.0</td>\n",
       "      <td>78400.0</td>\n",
       "      <td>74700.0</td>\n",
       "      <td>77200.0</td>\n",
       "      <td>462240.0</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>998.004622</td>\n",
       "      <td>1957.316939</td>\n",
       "      <td>80881.513600</td>\n",
       "      <td>...</td>\n",
       "      <td>6230936.0</td>\n",
       "      <td>924480000.0</td>\n",
       "      <td>14.15332</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.649949</td>\n",
       "      <td>화</td>\n",
       "      <td>181.916077</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>77200.0</td>\n",
       "      <td>77400.0</td>\n",
       "      <td>74200.0</td>\n",
       "      <td>75200.0</td>\n",
       "      <td>337977.0</td>\n",
       "      <td>-0.025907</td>\n",
       "      <td>733.731308</td>\n",
       "      <td>1712.599813</td>\n",
       "      <td>80426.622784</td>\n",
       "      <td>...</td>\n",
       "      <td>5892959.0</td>\n",
       "      <td>-675954000.0</td>\n",
       "      <td>14.04271</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.642103</td>\n",
       "      <td>수</td>\n",
       "      <td>21.082685</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>75600.0</td>\n",
       "      <td>76900.0</td>\n",
       "      <td>73600.0</td>\n",
       "      <td>74400.0</td>\n",
       "      <td>297806.0</td>\n",
       "      <td>-0.010638</td>\n",
       "      <td>454.500292</td>\n",
       "      <td>1460.979909</td>\n",
       "      <td>79999.025417</td>\n",
       "      <td>...</td>\n",
       "      <td>5595153.0</td>\n",
       "      <td>-238244800.0</td>\n",
       "      <td>13.70464</td>\n",
       "      <td>1.137340e+06</td>\n",
       "      <td>1.137340e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.834451</td>\n",
       "      <td>목</td>\n",
       "      <td>277.915244</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>74000.0</td>\n",
       "      <td>74400.0</td>\n",
       "      <td>71700.0</td>\n",
       "      <td>73900.0</td>\n",
       "      <td>441861.0</td>\n",
       "      <td>-0.006720</td>\n",
       "      <td>190.664023</td>\n",
       "      <td>1206.916732</td>\n",
       "      <td>79597.083892</td>\n",
       "      <td>...</td>\n",
       "      <td>5153292.0</td>\n",
       "      <td>-220930500.0</td>\n",
       "      <td>14.24473</td>\n",
       "      <td>2.964739e+06</td>\n",
       "      <td>2.964739e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.831200</td>\n",
       "      <td>금</td>\n",
       "      <td>318.234971</td>\n",
       "      <td>0.065548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2023-06-26</td>\n",
       "      <td>110300.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>109400.0</td>\n",
       "      <td>109700.0</td>\n",
       "      <td>193953.0</td>\n",
       "      <td>-0.011712</td>\n",
       "      <td>2278.430780</td>\n",
       "      <td>2139.225965</td>\n",
       "      <td>107945.212075</td>\n",
       "      <td>...</td>\n",
       "      <td>35864179.0</td>\n",
       "      <td>-252138900.0</td>\n",
       "      <td>16.79784</td>\n",
       "      <td>1.151153e+08</td>\n",
       "      <td>1.151153e+08</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>14.511251</td>\n",
       "      <td>월</td>\n",
       "      <td>94.132075</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2023-06-27</td>\n",
       "      <td>108600.0</td>\n",
       "      <td>110900.0</td>\n",
       "      <td>106400.0</td>\n",
       "      <td>109700.0</td>\n",
       "      <td>238510.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1879.125841</td>\n",
       "      <td>2087.205941</td>\n",
       "      <td>124300.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>35864179.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.64082</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.683814</td>\n",
       "      <td>화</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2023-06-28</td>\n",
       "      <td>109100.0</td>\n",
       "      <td>110200.0</td>\n",
       "      <td>107300.0</td>\n",
       "      <td>107300.0</td>\n",
       "      <td>213378.0</td>\n",
       "      <td>-0.021878</td>\n",
       "      <td>1353.412560</td>\n",
       "      <td>1940.447265</td>\n",
       "      <td>123942.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>35650801.0</td>\n",
       "      <td>-512107200.0</td>\n",
       "      <td>15.29111</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.727272</td>\n",
       "      <td>수</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2023-06-29</td>\n",
       "      <td>107400.0</td>\n",
       "      <td>110500.0</td>\n",
       "      <td>105300.0</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>258872.0</td>\n",
       "      <td>-0.002796</td>\n",
       "      <td>902.173807</td>\n",
       "      <td>1732.792573</td>\n",
       "      <td>123591.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>35391929.0</td>\n",
       "      <td>-77661600.0</td>\n",
       "      <td>15.00185</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.708174</td>\n",
       "      <td>목</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>108800.0</td>\n",
       "      <td>105200.0</td>\n",
       "      <td>106800.0</td>\n",
       "      <td>202510.0</td>\n",
       "      <td>-0.001869</td>\n",
       "      <td>522.403572</td>\n",
       "      <td>1490.714773</td>\n",
       "      <td>122859.513600</td>\n",
       "      <td>...</td>\n",
       "      <td>35189419.0</td>\n",
       "      <td>-40502000.0</td>\n",
       "      <td>16.08035</td>\n",
       "      <td>1.563737e+08</td>\n",
       "      <td>3.127473e+07</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.750628</td>\n",
       "      <td>금</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE      Open      High       Low     Close    Volume    Change  \\\n",
       "0   2023-01-02   77300.0   78000.0   73300.0   75200.0  425582.0 -0.019557   \n",
       "1   2023-01-03   74900.0   78400.0   74700.0   77200.0  462240.0  0.026596   \n",
       "2   2023-01-04   77200.0   77400.0   74200.0   75200.0  337977.0 -0.025907   \n",
       "3   2023-01-05   75600.0   76900.0   73600.0   74400.0  297806.0 -0.010638   \n",
       "4   2023-01-06   74000.0   74400.0   71700.0   73900.0  441861.0 -0.006720   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "118 2023-06-26  110300.0  112000.0  109400.0  109700.0  193953.0 -0.011712   \n",
       "119 2023-06-27  108600.0  110900.0  106400.0  109700.0  238510.0  0.000000   \n",
       "120 2023-06-28  109100.0  110200.0  107300.0  107300.0  213378.0 -0.021878   \n",
       "121 2023-06-29  107400.0  110500.0  105300.0  107000.0  258872.0 -0.002796   \n",
       "122 2023-06-30  107000.0  108800.0  105200.0  106800.0  202510.0 -0.001869   \n",
       "\n",
       "            MACD       Signal           PSAR  ...         OBV           FI  \\\n",
       "0    1117.160676  2197.145019   81365.440000  ...   5768696.0 -638373000.0   \n",
       "1     998.004622  1957.316939   80881.513600  ...   6230936.0  924480000.0   \n",
       "2     733.731308  1712.599813   80426.622784  ...   5892959.0 -675954000.0   \n",
       "3     454.500292  1460.979909   79999.025417  ...   5595153.0 -238244800.0   \n",
       "4     190.664023  1206.916732   79597.083892  ...   5153292.0 -220930500.0   \n",
       "..           ...          ...            ...  ...         ...          ...   \n",
       "118  2278.430780  2139.225965  107945.212075  ...  35864179.0 -252138900.0   \n",
       "119  1879.125841  2087.205941  124300.000000  ...  35864179.0          0.0   \n",
       "120  1353.412560  1940.447265  123942.000000  ...  35650801.0 -512107200.0   \n",
       "121   902.173807  1732.792573  123591.160000  ...  35391929.0  -77661600.0   \n",
       "122   522.403572  1490.714773  122859.513600  ...  35189419.0  -40502000.0   \n",
       "\n",
       "      keyword  view_log_like_sum  view_log_like_avg     count      trend  DAY  \\\n",
       "0    24.96469       1.511554e+08       3.023108e+07  2.500000  12.280464    월   \n",
       "1    14.15332       0.000000e+00       0.000000e+00  0.000000   2.649949    화   \n",
       "2    14.04271       0.000000e+00       0.000000e+00  0.000000   2.642103    수   \n",
       "3    13.70464       1.137340e+06       1.137340e+06  1.000000  16.834451    목   \n",
       "4    14.24473       2.964739e+06       2.964739e+06  1.000000  17.831200    금   \n",
       "..        ...                ...                ...       ...        ...  ...   \n",
       "118  16.79784       1.151153e+08       1.151153e+08  0.666667  14.511251    월   \n",
       "119  14.64082       0.000000e+00       0.000000e+00  0.000000   2.683814    화   \n",
       "120  15.29111       0.000000e+00       0.000000e+00  0.000000   2.727272    수   \n",
       "121  15.00185       0.000000e+00       0.000000e+00  0.000000   2.708174    목   \n",
       "122  16.08035       1.563737e+08       3.127473e+07  5.000000  20.750628    금   \n",
       "\n",
       "      SENTIMENT      EVENT  \n",
       "0     80.773832  24.993916  \n",
       "1    181.916077        NaN  \n",
       "2     21.082685        NaN  \n",
       "3    277.915244        NaN  \n",
       "4    318.234971   0.065548  \n",
       "..          ...        ...  \n",
       "118   94.132075        NaN  \n",
       "119         NaN        NaN  \n",
       "120         NaN        NaN  \n",
       "121         NaN        NaN  \n",
       "122         NaN        NaN  \n",
       "\n",
       "[127 rows x 26 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변수 이름 변경\n",
    "merged_df = merged_df.rename(columns={'SENTIMENT_SUM_x': 'SENTIMENT', 'SENTIMENT_SUM_y': 'EVENT'})\n",
    "merged_df = merged_df.drop(columns=['DAY', 'DAY_y'])\n",
    "\n",
    "# DAY_x 열을 DAY로 변경\n",
    "merged_df = merged_df.rename(columns={'DAY_x': 'DAY'})\n",
    "\n",
    "# 결과 출력\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22f55880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 127 entries, 0 to 122\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   DATE               127 non-null    datetime64[ns]\n",
      " 1   Open               123 non-null    float64       \n",
      " 2   High               123 non-null    float64       \n",
      " 3   Low                123 non-null    float64       \n",
      " 4   Close              123 non-null    float64       \n",
      " 5   Volume             123 non-null    float64       \n",
      " 6   Change             123 non-null    float64       \n",
      " 7   MACD               123 non-null    float64       \n",
      " 8   Signal             123 non-null    float64       \n",
      " 9   PSAR               123 non-null    float64       \n",
      " 10  upper              123 non-null    float64       \n",
      " 11  middle             123 non-null    float64       \n",
      " 12  lower              123 non-null    float64       \n",
      " 13  SlowK              123 non-null    float64       \n",
      " 14  SlowD              123 non-null    float64       \n",
      " 15  ROC                123 non-null    float64       \n",
      " 16  OBV                123 non-null    float64       \n",
      " 17  FI                 123 non-null    float64       \n",
      " 18  keyword            123 non-null    float64       \n",
      " 19  view_log_like_sum  123 non-null    float64       \n",
      " 20  view_log_like_avg  123 non-null    float64       \n",
      " 21  count              123 non-null    float64       \n",
      " 22  trend              123 non-null    float64       \n",
      " 23  DAY                123 non-null    object        \n",
      " 24  SENTIMENT          120 non-null    float64       \n",
      " 25  EVENT              42 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(24), object(1)\n",
      "memory usage: 26.8+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e792924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Change</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal</th>\n",
       "      <th>PSAR</th>\n",
       "      <th>...</th>\n",
       "      <th>OBV</th>\n",
       "      <th>FI</th>\n",
       "      <th>keyword</th>\n",
       "      <th>view_log_like_sum</th>\n",
       "      <th>view_log_like_avg</th>\n",
       "      <th>count</th>\n",
       "      <th>trend</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-74.969003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.226857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.952892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2023-05-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.772645</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE  Open  High  Low  Close  Volume  Change  MACD  Signal  PSAR  \\\n",
       "125 2023-03-01   NaN   NaN  NaN    NaN     NaN     NaN   NaN     NaN   NaN   \n",
       "123 2023-05-01   NaN   NaN  NaN    NaN     NaN     NaN   NaN     NaN   NaN   \n",
       "126 2023-05-05   NaN   NaN  NaN    NaN     NaN     NaN   NaN     NaN   NaN   \n",
       "124 2023-05-29   NaN   NaN  NaN    NaN     NaN     NaN   NaN     NaN   NaN   \n",
       "\n",
       "     ...  OBV  FI  keyword  view_log_like_sum  view_log_like_avg  count  \\\n",
       "125  ...  NaN NaN      NaN                NaN                NaN    NaN   \n",
       "123  ...  NaN NaN      NaN                NaN                NaN    NaN   \n",
       "126  ...  NaN NaN      NaN                NaN                NaN    NaN   \n",
       "124  ...  NaN NaN      NaN                NaN                NaN    NaN   \n",
       "\n",
       "     trend  DAY  SENTIMENT      EVENT  \n",
       "125    NaN  NaN        NaN -74.969003  \n",
       "123    NaN  NaN  22.226857        NaN  \n",
       "126    NaN  NaN        NaN  99.952892  \n",
       "124    NaN  NaN  21.772645        NaN  \n",
       "\n",
       "[4 rows x 26 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df['Open'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd7aff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23827/117352557.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[merged_df['DATE'] == '2023-05-02']['EVENT'] = (a+b)/2\n",
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23827/117352557.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[merged_df['DATE'] == '2023-05-02']['SENTIMENT'] = (c+d)/2\n"
     ]
    }
   ],
   "source": [
    "# 제거되지 않은 5월 1일의 데이터를 5월 2일 데이터와 병합\n",
    "a = float(merged_df[merged_df['DATE'] == '2023-05-01']['EVENT'])\n",
    "b = float(merged_df[merged_df['DATE'] == '2023-05-02']['EVENT'])\n",
    "merged_df[merged_df['DATE'] == '2023-05-02']['EVENT'] = (a+b)/2\n",
    "\n",
    "c = float(merged_df[merged_df['DATE'] == '2023-05-01']['SENTIMENT'])\n",
    "d = float(merged_df[merged_df['DATE'] == '2023-05-02']['SENTIMENT'])\n",
    "merged_df[merged_df['DATE'] == '2023-05-02']['SENTIMENT'] = (c+d)/2\n",
    "\n",
    "merged_df = merged_df[merged_df['DATE'] != '2023-05-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fdede33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23827/1842193291.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[merged_df['DATE'] == '2023-05-30']['EVENT'] = (a+b)/2\n",
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23827/1842193291.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[merged_df['DATE'] == '2023-05-30']['SENTIMENT'] = (c+d)/2\n"
     ]
    }
   ],
   "source": [
    "# 제거되지 않은 5월 29일의 데이터를 5월 30일 데이터와 병합\n",
    "a = float(merged_df[merged_df['DATE'] == '2023-05-29']['EVENT'])\n",
    "b = float(merged_df[merged_df['DATE'] == '2023-05-30']['EVENT'])\n",
    "merged_df[merged_df['DATE'] == '2023-05-30']['EVENT'] = (a+b)/2\n",
    "\n",
    "c = float(merged_df[merged_df['DATE'] == '2023-05-29']['SENTIMENT'])\n",
    "d = float(merged_df[merged_df['DATE'] == '2023-05-30']['SENTIMENT'])\n",
    "merged_df[merged_df['DATE'] == '2023-05-30']['SENTIMENT'] = (c+d)/2\n",
    "\n",
    "merged_df = merged_df[merged_df['DATE'] != '2023-05-29']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d44a868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23827/443569746.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[merged_df['DATE'] == '2023-05-08']['EVENT'] = (a+b)/2\n",
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23827/443569746.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[merged_df['DATE'] == '2023-05-08']['SENTIMENT'] = (c+d)/2\n"
     ]
    }
   ],
   "source": [
    "# 제거되지 않은 5월 5일의 데이터를 5월 8일 데이터와 병합\n",
    "a = float(merged_df[merged_df['DATE'] == '2023-05-05']['EVENT'])\n",
    "b = float(merged_df[merged_df['DATE'] == '2023-05-08']['EVENT'])\n",
    "merged_df[merged_df['DATE'] == '2023-05-08']['EVENT'] = (a+b)/2\n",
    "\n",
    "c = float(merged_df[merged_df['DATE'] == '2023-05-05']['SENTIMENT'])\n",
    "d = float(merged_df[merged_df['DATE'] == '2023-05-08']['SENTIMENT'])\n",
    "merged_df[merged_df['DATE'] == '2023-05-08']['SENTIMENT'] = (c+d)/2\n",
    "\n",
    "merged_df = merged_df[merged_df['DATE'] != '2023-05-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b762246c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23827/150931787.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[merged_df['DATE'] == '2023-03-02']['EVENT'] = (a+b)/2\n",
      "/var/folders/4t/dyhc70gd7zjdwxdh7x7f77240000gn/T/ipykernel_23827/150931787.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[merged_df['DATE'] == '2023-03-02']['SENTIMENT'] = (c+d)/2\n"
     ]
    }
   ],
   "source": [
    "# 제거되지 않은 3월 1일의 데이터를 3월 2일의 데이터와 병합\n",
    "a = float(merged_df[merged_df['DATE'] == '2023-03-01']['EVENT'])\n",
    "b = float(merged_df[merged_df['DATE'] == '2023-03-02']['EVENT'])\n",
    "merged_df[merged_df['DATE'] == '2023-03-02']['EVENT'] = (a+b)/2\n",
    "\n",
    "c = float(merged_df[merged_df['DATE'] == '2023-03-01']['SENTIMENT'])\n",
    "d = float(merged_df[merged_df['DATE'] == '2023-03-02']['SENTIMENT'])\n",
    "merged_df[merged_df['DATE'] == '2023-03-02']['SENTIMENT'] = (c+d)/2\n",
    "\n",
    "merged_df = merged_df[merged_df['DATE'] != '2023-03-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3b2a70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 123 entries, 0 to 122\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   DATE               123 non-null    datetime64[ns]\n",
      " 1   Open               123 non-null    float64       \n",
      " 2   High               123 non-null    float64       \n",
      " 3   Low                123 non-null    float64       \n",
      " 4   Close              123 non-null    float64       \n",
      " 5   Volume             123 non-null    float64       \n",
      " 6   Change             123 non-null    float64       \n",
      " 7   MACD               123 non-null    float64       \n",
      " 8   Signal             123 non-null    float64       \n",
      " 9   PSAR               123 non-null    float64       \n",
      " 10  upper              123 non-null    float64       \n",
      " 11  middle             123 non-null    float64       \n",
      " 12  lower              123 non-null    float64       \n",
      " 13  SlowK              123 non-null    float64       \n",
      " 14  SlowD              123 non-null    float64       \n",
      " 15  ROC                123 non-null    float64       \n",
      " 16  OBV                123 non-null    float64       \n",
      " 17  FI                 123 non-null    float64       \n",
      " 18  keyword            123 non-null    float64       \n",
      " 19  view_log_like_sum  123 non-null    float64       \n",
      " 20  view_log_like_avg  123 non-null    float64       \n",
      " 21  count              123 non-null    float64       \n",
      " 22  trend              123 non-null    float64       \n",
      " 23  DAY                123 non-null    object        \n",
      " 24  SENTIMENT          118 non-null    float64       \n",
      " 25  EVENT              40 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(24), object(1)\n",
      "memory usage: 25.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# 확인\n",
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ab6f3",
   "metadata": {},
   "source": [
    "# CSV 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e73a2dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"../../data/FINALDATA/sm.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "270.885px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
